{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf  \n",
    "import numpy as np       \n",
    "import pandas as pd       \n",
    "from matplotlib import pyplot as plt   \n",
    "import seaborn as sns  \n",
    "import time          \n",
    "from tensorflow.keras.callbacks import History, ReduceLROnPlateau, TensorBoard       \n",
    "from tensorflow.keras import metrics          \n",
    "from sklearn.metrics import confusion_matrix          \n",
    "import pickle\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Reshape, multiply, add, Dense, Conv2D, GlobalMaxPooling2D, Activation\n",
    "from tensorflow.keras import backend as K\n",
    "import platform\n",
    "import os\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Multiply, Dense\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Multiply\n",
    "import platform\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display Settings\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:  3.11.7\n",
      "TensorFlow version:  2.15.0\n",
      "Current working directory:  /root/.jupyter/张彤/消融实验\n",
      "Linux w3q2ulc9.vm 5.15.0-60-generic #66-Ubuntu SMP Fri Jan 20 14:29:49 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux\n",
      "Sun Oct 27 20:33:54 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        On  | 00000000:09:00.0 Off |                  Off |\n",
      "|  0%   24C    P8              11W / 450W |      3MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 4090        On  | 00000000:0B:00.0 Off |                  Off |\n",
      "|  0%   26C    P8               9W / 450W |      3MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# System Information Print the Python version\n",
    "print(\"Python version: \", platform.python_version())\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "print(\"Current working directory: \", os.getcwd())\n",
    "!uname -a\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameter Settings\n",
    "EPOCHS = 50\n",
    "IMAGE_SIZE = (224, 224)\n",
    "IMAGE_PATH = \"../data\"\n",
    "LEARNING_RATE = 1e-4\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14080 files belonging to 100 classes.\n",
      "Using 11264 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-27 20:33:59.571707: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-27 20:33:59.572209: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-27 20:33:59.848375: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-27 20:33:59.849064: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-27 20:33:59.849492: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-27 20:33:59.849887: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-27 20:34:00.127871: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-27 20:34:00.128196: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-27 20:34:00.128400: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-27 20:34:00.128580: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-27 20:34:00.128757: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-27 20:34:00.128937: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-27 20:34:00.148006: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-27 20:34:00.148284: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-27 20:34:00.148496: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-27 20:34:00.148697: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-27 20:34:00.148899: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-27 20:34:00.149070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22287 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:09:00.0, compute capability: 8.9\n",
      "2024-10-27 20:34:00.150042: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-27 20:34:00.150243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22287 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:0b:00.0, compute capability: 8.9\n",
      "2024-10-27 20:34:01.074674: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14080 files belonging to 100 classes.\n",
      "Using 2816 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    IMAGE_PATH,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",    \n",
    "    seed=123,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "vaild_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    IMAGE_PATH,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Image Normalization\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "def normalize_image(image):\n",
    "    return (image - mean_tensor) / std_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "train_image_augment = tf.keras.Sequential([\n",
    "    tf.keras.layers.Rescaling(1 / 255.0),\n",
    "    tf.keras.layers.RandomRotation(factor=0.2),\n",
    "    tf.keras.layers.RandomFlip(),\n",
    "])\n",
    "\n",
    "valid_image_augment = tf.keras.Sequential([\n",
    "    tf.keras.layers.Rescaling(1 / 255.0),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input Processing\n",
    "def process_train_input(images, labels):\n",
    "    return train_image_augment(images), labels\n",
    "\n",
    "def process_valid_input(images, labels):\n",
    "    return valid_image_augment(images), labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "def convert_types_and_encode(x, y):\n",
    "    y = tf.cast(y, tf.int32)  \n",
    "    y_one_hot = tf.one_hot(y, 100)  \n",
    "    return x, y_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply Data Preprocessing\n",
    "train_ds = train_ds.map(convert_types_and_encode)\n",
    "train_ds = train_ds.map(process_train_input, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "vaild_ds = vaild_ds.map(convert_types_and_encode)\n",
    "vaild_ds = vaild_ds.map(process_valid_input, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "vaild_ds = vaild_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Functional model inputs must come from `tf.keras.Input` (thus holding past layer metadata). They cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"model\" was not an Input tensor, it was generated by layer \"input_1\".\n",
      "Note that input tensors are instantiated via `tensor = tf.keras.Input(shape)`.\n",
      "The tensor that caused the issue was: KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D, Multiply, Dense\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# Define the modified ECA layer, which now supports partial channel selection\n",
    "def eca_layer(input_tensor, k_size=3, partial_ratio=0.25):\n",
    "    \"\"\"Efficient Channel Attention (ECA) for a portion of the channels.\n",
    "    \n",
    "    Args:\n",
    "        input_tensor: The input feature map (batch_size, height, width, channels).\n",
    "        k_size: Kernel size for the 1D convolution used in ECA.\n",
    "        partial_ratio: Ratio of channels to apply ECA on. In this case, 0.25 means applying ECA on 25% of the channels.\n",
    "    \n",
    "    Returns:\n",
    "        The output tensor after applying ECA on the selected channels.\n",
    "    \"\"\"\n",
    "    channels = input_tensor.shape[-1]  # Get the total number of channels\n",
    "    partial_channels = int(channels * partial_ratio)  # Calculate the number of channels to apply ECA\n",
    "\n",
    "    # Split the input tensor into two parts: the first part to apply ECA and the second part to leave unchanged\n",
    "    eca_part = input_tensor[:, :, :, :partial_channels]\n",
    "    non_eca_part = input_tensor[:, :, :, partial_channels:]\n",
    "    \n",
    "    # Apply global average pooling to the selected channels\n",
    "    avg_pool = tf.reduce_mean(eca_part, axis=[1, 2], keepdims=True)  # (batch_size, 1, 1, partial_channels)\n",
    "    \n",
    "    # Apply 1D convolution (as Conv2D with (k_size, 1) kernel) to capture cross-channel dependencies\n",
    "    conv = Conv2D(filters=partial_channels, kernel_size=(k_size, 1), padding='same', activation='sigmoid')(avg_pool)\n",
    "    \n",
    "    # Multiply the attention map with the input feature maps (only for the selected channels)\n",
    "    weighted_eca_part = Multiply()([eca_part, conv])  # (batch_size, height, width, partial_channels)\n",
    "    \n",
    "    # Concatenate the processed ECA part with the unchanged part\n",
    "    output = tf.concat([weighted_eca_part, non_eca_part], axis=-1)\n",
    "\n",
    "    return output\n",
    "\n",
    "# Create MobileNet base model (or any other backbone)\n",
    "base_model = tf.keras.applications.MobileNet(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "\n",
    "# Select the low-level layers to apply ECA\n",
    "# For low-level features, we can apply ECA to the first couple of layers like 'conv1_relu' and 'conv_dw_1_relu'\n",
    "selected_layers = ['conv1_relu', 'conv_dw_1_relu']  # Example low-level layers, you can modify based on your needs\n",
    "\n",
    "# Apply ECA only to the selected layers (low-level features)\n",
    "x = base_model.input\n",
    "for layer in base_model.layers:\n",
    "    x = layer(x)\n",
    "    if layer.name in selected_layers:\n",
    "        x = eca_layer(x, k_size=5, partial_ratio=0.75)  # Apply ECA to the selected low-level layers with 75% channels\n",
    "\n",
    "# Add global average pooling\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add fully connected layers\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "outputs = Dense(100, activation='softmax')(x)  # Adjust the number of classes as needed\n",
    "\n",
    "# Create the final model\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "metrics = [\n",
    "    tf.keras.metrics.CategoricalAccuracy(),\n",
    "    tf.keras.metrics.Precision(),\n",
    "    tf.keras.metrics.Recall(),\n",
    "]\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-27 20:34:28.262292: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-10-27 20:34:28.617681: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-10-27 20:34:29.848231: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f97cc0d2c80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-10-27 20:34:29.848301: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2024-10-27 20:34:29.848317: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2024-10-27 20:34:29.878490: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730032470.124567    1629 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 35s 85ms/step - loss: 2.5645 - categorical_accuracy: 0.4348 - precision: 0.8851 - recall: 0.1887 - val_loss: 2.9533 - val_categorical_accuracy: 0.3097 - val_precision: 0.6943 - val_recall: 0.1129 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "176/176 [==============================] - 14s 77ms/step - loss: 0.9779 - categorical_accuracy: 0.7499 - precision: 0.9067 - recall: 0.5884 - val_loss: 0.9189 - val_categorical_accuracy: 0.7589 - val_precision: 0.8961 - val_recall: 0.6126 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "176/176 [==============================] - 15s 81ms/step - loss: 0.6260 - categorical_accuracy: 0.8276 - precision: 0.9213 - recall: 0.7335 - val_loss: 0.7173 - val_categorical_accuracy: 0.7912 - val_precision: 0.8874 - val_recall: 0.7024 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "176/176 [==============================] - 16s 85ms/step - loss: 0.4445 - categorical_accuracy: 0.8785 - precision: 0.9372 - recall: 0.8109 - val_loss: 0.5836 - val_categorical_accuracy: 0.8370 - val_precision: 0.9043 - val_recall: 0.7752 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "176/176 [==============================] - 15s 81ms/step - loss: 0.3349 - categorical_accuracy: 0.9088 - precision: 0.9536 - recall: 0.8613 - val_loss: 0.5307 - val_categorical_accuracy: 0.8519 - val_precision: 0.9130 - val_recall: 0.8008 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "176/176 [==============================] - 15s 85ms/step - loss: 0.2655 - categorical_accuracy: 0.9268 - precision: 0.9580 - recall: 0.8916 - val_loss: 0.5024 - val_categorical_accuracy: 0.8597 - val_precision: 0.9081 - val_recall: 0.8171 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "176/176 [==============================] - 16s 86ms/step - loss: 0.2004 - categorical_accuracy: 0.9459 - precision: 0.9696 - recall: 0.9220 - val_loss: 0.4530 - val_categorical_accuracy: 0.8757 - val_precision: 0.9154 - val_recall: 0.8448 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "176/176 [==============================] - 16s 85ms/step - loss: 0.1599 - categorical_accuracy: 0.9593 - precision: 0.9736 - recall: 0.9374 - val_loss: 0.4499 - val_categorical_accuracy: 0.8732 - val_precision: 0.9117 - val_recall: 0.8438 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "176/176 [==============================] - 16s 86ms/step - loss: 0.1327 - categorical_accuracy: 0.9664 - precision: 0.9780 - recall: 0.9518 - val_loss: 0.4573 - val_categorical_accuracy: 0.8718 - val_precision: 0.9050 - val_recall: 0.8455 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "176/176 [==============================] - 16s 86ms/step - loss: 0.0952 - categorical_accuracy: 0.9775 - precision: 0.9838 - recall: 0.9674 - val_loss: 0.4125 - val_categorical_accuracy: 0.8874 - val_precision: 0.9216 - val_recall: 0.8597 - lr: 5.0000e-05\n",
      "Epoch 11/50\n",
      "176/176 [==============================] - 16s 85ms/step - loss: 0.0830 - categorical_accuracy: 0.9806 - precision: 0.9850 - recall: 0.9709 - val_loss: 0.3948 - val_categorical_accuracy: 0.8906 - val_precision: 0.9239 - val_recall: 0.8707 - lr: 5.0000e-05\n",
      "Epoch 12/50\n",
      "176/176 [==============================] - 15s 81ms/step - loss: 0.0721 - categorical_accuracy: 0.9832 - precision: 0.9877 - recall: 0.9773 - val_loss: 0.3956 - val_categorical_accuracy: 0.8974 - val_precision: 0.9195 - val_recall: 0.8764 - lr: 5.0000e-05\n",
      "Epoch 13/50\n",
      "176/176 [==============================] - 15s 85ms/step - loss: 0.0661 - categorical_accuracy: 0.9862 - precision: 0.9899 - recall: 0.9792 - val_loss: 0.3714 - val_categorical_accuracy: 0.8984 - val_precision: 0.9264 - val_recall: 0.8807 - lr: 5.0000e-05\n",
      "Epoch 14/50\n",
      "176/176 [==============================] - 15s 84ms/step - loss: 0.0594 - categorical_accuracy: 0.9862 - precision: 0.9892 - recall: 0.9811 - val_loss: 0.3641 - val_categorical_accuracy: 0.9052 - val_precision: 0.9289 - val_recall: 0.8857 - lr: 5.0000e-05\n",
      "Epoch 15/50\n",
      "176/176 [==============================] - 16s 85ms/step - loss: 0.0569 - categorical_accuracy: 0.9876 - precision: 0.9893 - recall: 0.9833 - val_loss: 0.3650 - val_categorical_accuracy: 0.9027 - val_precision: 0.9282 - val_recall: 0.8857 - lr: 5.0000e-05\n",
      "Epoch 16/50\n",
      "176/176 [==============================] - 15s 81ms/step - loss: 0.0531 - categorical_accuracy: 0.9877 - precision: 0.9903 - recall: 0.9853 - val_loss: 0.3783 - val_categorical_accuracy: 0.8942 - val_precision: 0.9199 - val_recall: 0.8771 - lr: 5.0000e-05\n",
      "Epoch 17/50\n",
      "176/176 [==============================] - 15s 80ms/step - loss: 0.0433 - categorical_accuracy: 0.9898 - precision: 0.9915 - recall: 0.9876 - val_loss: 0.3539 - val_categorical_accuracy: 0.9080 - val_precision: 0.9280 - val_recall: 0.8885 - lr: 2.5000e-05\n",
      "Epoch 18/50\n",
      "176/176 [==============================] - 16s 85ms/step - loss: 0.0388 - categorical_accuracy: 0.9919 - precision: 0.9932 - recall: 0.9903 - val_loss: 0.3527 - val_categorical_accuracy: 0.9045 - val_precision: 0.9234 - val_recall: 0.8903 - lr: 2.5000e-05\n",
      "Epoch 19/50\n",
      "176/176 [==============================] - 15s 84ms/step - loss: 0.0360 - categorical_accuracy: 0.9928 - precision: 0.9936 - recall: 0.9914 - val_loss: 0.3537 - val_categorical_accuracy: 0.9070 - val_precision: 0.9280 - val_recall: 0.8931 - lr: 2.5000e-05\n",
      "Epoch 20/50\n",
      "176/176 [==============================] - 16s 86ms/step - loss: 0.0320 - categorical_accuracy: 0.9934 - precision: 0.9941 - recall: 0.9923 - val_loss: 0.3480 - val_categorical_accuracy: 0.9073 - val_precision: 0.9255 - val_recall: 0.8910 - lr: 1.2500e-05\n",
      "Epoch 21/50\n",
      "176/176 [==============================] - 16s 87ms/step - loss: 0.0322 - categorical_accuracy: 0.9920 - precision: 0.9932 - recall: 0.9911 - val_loss: 0.3454 - val_categorical_accuracy: 0.9080 - val_precision: 0.9264 - val_recall: 0.8942 - lr: 1.2500e-05\n",
      "Epoch 22/50\n",
      "176/176 [==============================] - 16s 86ms/step - loss: 0.0296 - categorical_accuracy: 0.9943 - precision: 0.9947 - recall: 0.9933 - val_loss: 0.3419 - val_categorical_accuracy: 0.9087 - val_precision: 0.9254 - val_recall: 0.8942 - lr: 6.2500e-06\n",
      "Epoch 23/50\n",
      "176/176 [==============================] - 15s 81ms/step - loss: 0.0283 - categorical_accuracy: 0.9951 - precision: 0.9956 - recall: 0.9941 - val_loss: 0.3445 - val_categorical_accuracy: 0.9077 - val_precision: 0.9253 - val_recall: 0.8931 - lr: 6.2500e-06\n",
      "Epoch 24/50\n",
      "176/176 [==============================] - 16s 86ms/step - loss: 0.0274 - categorical_accuracy: 0.9945 - precision: 0.9949 - recall: 0.9932 - val_loss: 0.3426 - val_categorical_accuracy: 0.9102 - val_precision: 0.9255 - val_recall: 0.8952 - lr: 6.2500e-06\n",
      "Epoch 25/50\n",
      "176/176 [==============================] - 16s 87ms/step - loss: 0.0296 - categorical_accuracy: 0.9933 - precision: 0.9940 - recall: 0.9922 - val_loss: 0.3429 - val_categorical_accuracy: 0.9094 - val_precision: 0.9283 - val_recall: 0.8960 - lr: 6.2500e-06\n",
      "Epoch 26/50\n",
      "176/176 [==============================] - 16s 85ms/step - loss: 0.0288 - categorical_accuracy: 0.9939 - precision: 0.9940 - recall: 0.9931 - val_loss: 0.3426 - val_categorical_accuracy: 0.9105 - val_precision: 0.9294 - val_recall: 0.8977 - lr: 6.2500e-06\n",
      "Epoch 27/50\n",
      "176/176 [==============================] - 16s 85ms/step - loss: 0.0277 - categorical_accuracy: 0.9933 - precision: 0.9942 - recall: 0.9925 - val_loss: 0.3442 - val_categorical_accuracy: 0.9098 - val_precision: 0.9304 - val_recall: 0.8967 - lr: 6.2500e-06\n",
      "Epoch 28/50\n",
      "176/176 [==============================] - 16s 86ms/step - loss: 0.0272 - categorical_accuracy: 0.9942 - precision: 0.9948 - recall: 0.9936 - val_loss: 0.3429 - val_categorical_accuracy: 0.9098 - val_precision: 0.9292 - val_recall: 0.8945 - lr: 6.2500e-06\n",
      "Epoch 29/50\n",
      "176/176 [==============================] - 16s 86ms/step - loss: 0.0254 - categorical_accuracy: 0.9944 - precision: 0.9951 - recall: 0.9935 - val_loss: 0.3448 - val_categorical_accuracy: 0.9084 - val_precision: 0.9260 - val_recall: 0.8935 - lr: 3.1250e-06\n",
      "Epoch 30/50\n",
      "176/176 [==============================] - 16s 85ms/step - loss: 0.0262 - categorical_accuracy: 0.9941 - precision: 0.9942 - recall: 0.9934 - val_loss: 0.3430 - val_categorical_accuracy: 0.9112 - val_precision: 0.9297 - val_recall: 0.8967 - lr: 3.1250e-06\n",
      "Epoch 31/50\n",
      "176/176 [==============================] - 15s 84ms/step - loss: 0.0255 - categorical_accuracy: 0.9942 - precision: 0.9944 - recall: 0.9933 - val_loss: 0.3439 - val_categorical_accuracy: 0.9105 - val_precision: 0.9273 - val_recall: 0.8970 - lr: 3.1250e-06\n",
      "Epoch 32/50\n",
      "176/176 [==============================] - 15s 83ms/step - loss: 0.0260 - categorical_accuracy: 0.9948 - precision: 0.9948 - recall: 0.9938 - val_loss: 0.3415 - val_categorical_accuracy: 0.9080 - val_precision: 0.9273 - val_recall: 0.8970 - lr: 3.1250e-06\n",
      "Epoch 33/50\n",
      "176/176 [==============================] - 16s 85ms/step - loss: 0.0247 - categorical_accuracy: 0.9948 - precision: 0.9950 - recall: 0.9940 - val_loss: 0.3415 - val_categorical_accuracy: 0.9091 - val_precision: 0.9269 - val_recall: 0.8963 - lr: 1.5625e-06\n",
      "Epoch 34/50\n",
      "176/176 [==============================] - 16s 85ms/step - loss: 0.0251 - categorical_accuracy: 0.9951 - precision: 0.9955 - recall: 0.9945 - val_loss: 0.3417 - val_categorical_accuracy: 0.9102 - val_precision: 0.9260 - val_recall: 0.8970 - lr: 1.5625e-06\n",
      "Epoch 35/50\n",
      "176/176 [==============================] - 16s 86ms/step - loss: 0.0241 - categorical_accuracy: 0.9950 - precision: 0.9953 - recall: 0.9943 - val_loss: 0.3410 - val_categorical_accuracy: 0.9116 - val_precision: 0.9274 - val_recall: 0.8977 - lr: 7.8125e-07\n",
      "Epoch 36/50\n",
      "176/176 [==============================] - 15s 80ms/step - loss: 0.0251 - categorical_accuracy: 0.9943 - precision: 0.9947 - recall: 0.9936 - val_loss: 0.3418 - val_categorical_accuracy: 0.9084 - val_precision: 0.9269 - val_recall: 0.8967 - lr: 7.8125e-07\n",
      "Epoch 37/50\n",
      "176/176 [==============================] - 15s 83ms/step - loss: 0.0252 - categorical_accuracy: 0.9943 - precision: 0.9949 - recall: 0.9937 - val_loss: 0.3421 - val_categorical_accuracy: 0.9102 - val_precision: 0.9270 - val_recall: 0.8974 - lr: 7.8125e-07\n",
      "Epoch 38/50\n",
      "176/176 [==============================] - 15s 83ms/step - loss: 0.0236 - categorical_accuracy: 0.9949 - precision: 0.9952 - recall: 0.9944 - val_loss: 0.3420 - val_categorical_accuracy: 0.9087 - val_precision: 0.9266 - val_recall: 0.8970 - lr: 3.9062e-07\n",
      "Epoch 39/50\n",
      "176/176 [==============================] - 15s 82ms/step - loss: 0.0232 - categorical_accuracy: 0.9951 - precision: 0.9956 - recall: 0.9941 - val_loss: 0.3419 - val_categorical_accuracy: 0.9098 - val_precision: 0.9270 - val_recall: 0.8974 - lr: 3.9062e-07\n",
      "Epoch 40/50\n",
      "176/176 [==============================] - 15s 79ms/step - loss: 0.0239 - categorical_accuracy: 0.9952 - precision: 0.9955 - recall: 0.9940 - val_loss: 0.3417 - val_categorical_accuracy: 0.9102 - val_precision: 0.9267 - val_recall: 0.8974 - lr: 1.9531e-07\n",
      "Epoch 41/50\n",
      "176/176 [==============================] - 16s 85ms/step - loss: 0.0236 - categorical_accuracy: 0.9965 - precision: 0.9965 - recall: 0.9956 - val_loss: 0.3416 - val_categorical_accuracy: 0.9105 - val_precision: 0.9270 - val_recall: 0.8974 - lr: 1.9531e-07\n",
      "Epoch 42/50\n",
      "176/176 [==============================] - 14s 79ms/step - loss: 0.0240 - categorical_accuracy: 0.9945 - precision: 0.9946 - recall: 0.9941 - val_loss: 0.3417 - val_categorical_accuracy: 0.9102 - val_precision: 0.9277 - val_recall: 0.8974 - lr: 9.7656e-08\n",
      "Epoch 43/50\n",
      "176/176 [==============================] - 15s 81ms/step - loss: 0.0234 - categorical_accuracy: 0.9951 - precision: 0.9956 - recall: 0.9948 - val_loss: 0.3418 - val_categorical_accuracy: 0.9109 - val_precision: 0.9267 - val_recall: 0.8974 - lr: 9.7656e-08\n",
      "Epoch 44/50\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0229 - categorical_accuracy: 0.9957 - precision: 0.9960 - recall: 0.9952 - val_loss: 0.3418 - val_categorical_accuracy: 0.9102 - val_precision: 0.9273 - val_recall: 0.8974 - lr: 4.8828e-08\n",
      "Epoch 45/50\n",
      "176/176 [==============================] - 15s 83ms/step - loss: 0.0244 - categorical_accuracy: 0.9951 - precision: 0.9954 - recall: 0.9941 - val_loss: 0.3416 - val_categorical_accuracy: 0.9109 - val_precision: 0.9270 - val_recall: 0.8970 - lr: 4.8828e-08\n",
      "Epoch 46/50\n",
      "176/176 [==============================] - 15s 82ms/step - loss: 0.0248 - categorical_accuracy: 0.9948 - precision: 0.9950 - recall: 0.9940 - val_loss: 0.3413 - val_categorical_accuracy: 0.9109 - val_precision: 0.9270 - val_recall: 0.8970 - lr: 2.4414e-08\n",
      "Epoch 47/50\n",
      "176/176 [==============================] - 15s 81ms/step - loss: 0.0247 - categorical_accuracy: 0.9948 - precision: 0.9953 - recall: 0.9942 - val_loss: 0.3417 - val_categorical_accuracy: 0.9105 - val_precision: 0.9270 - val_recall: 0.8970 - lr: 2.4414e-08\n",
      "Epoch 48/50\n",
      "176/176 [==============================] - 14s 79ms/step - loss: 0.0236 - categorical_accuracy: 0.9949 - precision: 0.9954 - recall: 0.9943 - val_loss: 0.3417 - val_categorical_accuracy: 0.9105 - val_precision: 0.9273 - val_recall: 0.8967 - lr: 1.2207e-08\n",
      "Epoch 49/50\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0239 - categorical_accuracy: 0.9956 - precision: 0.9958 - recall: 0.9953 - val_loss: 0.3411 - val_categorical_accuracy: 0.9109 - val_precision: 0.9267 - val_recall: 0.8974 - lr: 1.2207e-08\n",
      "Epoch 50/50\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0244 - categorical_accuracy: 0.9949 - precision: 0.9954 - recall: 0.9944 - val_loss: 0.3416 - val_categorical_accuracy: 0.9105 - val_precision: 0.9263 - val_recall: 0.8967 - lr: 1.0000e-08\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "log_dir = \"../Running result/substratum/substratum\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=2, min_lr=1e-8)\n",
    "\n",
    "history = model.fit(train_ds, epochs=EPOCHS, validation_data=vaild_ds, callbacks=[lr_scheduler, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training history saved to: ../Running result/substratum/substratum/substratum.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: ../Running result/substratum/substratum/substratum.h5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # Import the Pandas library\n",
    "import os\n",
    "\n",
    "# Define save paths\n",
    "model_dir = \"../Running result/substratum/substratum\"\n",
    "excel_file_path = os.path.join(model_dir, \"substratum.xlsx\")  # Path to save the Excel file\n",
    "model_file_path = os.path.join(model_dir, \"substratum.h5\")  # Path to save the model\n",
    "\n",
    "# Check if the save directory exists, and create it if it does not\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "# Save training history to an Excel file\n",
    "history_df = pd.DataFrame(history.history)  \n",
    "history_df.to_excel(excel_file_path, index=False)\n",
    "print(f\"Training history saved to: {excel_file_path}\")\n",
    "\n",
    "# Save the model to the specified path\n",
    "model.save(model_file_path)\n",
    "print(f\"Model saved to: {model_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-27 18:30:42.673559: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-27 18:30:42.725328: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-27 18:30:42.725361: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-27 18:30:42.726600: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-27 18:30:42.735320: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-27 18:30:43.696113: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf  \n",
    "import numpy as np       \n",
    "import pandas as pd       \n",
    "from matplotlib import pyplot as plt   \n",
    "import seaborn as sns  \n",
    "import time          \n",
    "from tensorflow.keras.callbacks import History, ReduceLROnPlateau, TensorBoard       \n",
    "from tensorflow.keras import metrics          \n",
    "from sklearn.metrics import confusion_matrix          \n",
    "import pickle\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Reshape, multiply, add, Dense, Conv2D, GlobalMaxPooling2D, Activation\n",
    "from tensorflow.keras import backend as K\n",
    "import platform\n",
    "import os\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Multiply, Dense\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Multiply\n",
    "import platform\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display Settings\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:  3.11.7\n",
      "TensorFlow version:  2.15.0\n",
      "Current working directory:  /root/.jupyter/张彤/消融实验\n",
      "Linux w3q2ulc9.vm 5.15.0-60-generic #66-Ubuntu SMP Fri Jan 20 14:29:49 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux\n",
      "Sun Oct 27 18:30:46 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        On  | 00000000:09:00.0 Off |                  Off |\n",
      "|  0%   24C    P8              11W / 450W |      3MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 4090        On  | 00000000:0B:00.0 Off |                  Off |\n",
      "|  0%   25C    P8               3W / 450W |      3MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# System Information Print the Python version\n",
    "print(\"Python version: \", platform.python_version())\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "print(\"Current working directory: \", os.getcwd())\n",
    "!uname -a\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameter Settings\n",
    "EPOCHS = 50\n",
    "IMAGE_SIZE = (224, 224)\n",
    "IMAGE_PATH = \"../data\"\n",
    "LEARNING_RATE = 1e-4\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14080 files belonging to 100 classes.\n",
      "Using 11264 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-27 18:30:49.302596: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-27 18:30:49.303002: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-27 18:30:49.432349: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-27 18:30:49.432641: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-27 18:30:49.432811: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-27 18:30:49.432969: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-27 18:30:49.615924: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-27 18:30:49.616185: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-27 18:30:49.616355: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-27 18:30:49.616509: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-27 18:30:49.616657: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-27 18:30:49.616807: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-27 18:30:49.632415: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-27 18:30:49.632646: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-27 18:30:49.632836: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-27 18:30:49.633006: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-27 18:30:49.633177: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-27 18:30:49.633307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22287 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:09:00.0, compute capability: 8.9\n",
      "2024-10-27 18:30:49.634028: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-27 18:30:49.634175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22287 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:0b:00.0, compute capability: 8.9\n",
      "2024-10-27 18:30:50.281778: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14080 files belonging to 100 classes.\n",
      "Using 2816 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    IMAGE_PATH,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",    \n",
    "    seed=123,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "vaild_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    IMAGE_PATH,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Image Normalization\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "def normalize_image(image):\n",
    "    return (image - mean_tensor) / std_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "train_image_augment = tf.keras.Sequential([\n",
    "    tf.keras.layers.Rescaling(1 / 255.0),\n",
    "    tf.keras.layers.RandomRotation(factor=0.2),\n",
    "    tf.keras.layers.RandomFlip(),\n",
    "])\n",
    "\n",
    "valid_image_augment = tf.keras.Sequential([\n",
    "    tf.keras.layers.Rescaling(1 / 255.0),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input Processing\n",
    "def process_train_input(images, labels):\n",
    "    return train_image_augment(images), labels\n",
    "\n",
    "def process_valid_input(images, labels):\n",
    "    return valid_image_augment(images), labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "def convert_types_and_encode(x, y):\n",
    "    y = tf.cast(y, tf.int32)  \n",
    "    y_one_hot = tf.one_hot(y, 100)  \n",
    "    return x, y_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply Data Preprocessing\n",
    "train_ds = train_ds.map(convert_types_and_encode)\n",
    "train_ds = train_ds.map(process_train_input, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "vaild_ds = vaild_ds.map(convert_types_and_encode)\n",
    "vaild_ds = vaild_ds.map(process_valid_input, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "vaild_ds = vaild_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D, Multiply, Dense\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# Define the modified ECA layer, which now supports partial channel selection\n",
    "def eca_layer(input_tensor, k_size=3, partial_ratio=0.5):\n",
    "    \"\"\"Efficient Channel Attention (ECA) for a portion of the channels.\n",
    "    \n",
    "    Args:\n",
    "        input_tensor: The input feature map (batch_size, height, width, channels).\n",
    "        k_size: Kernel size for the 1D convolution used in ECA.\n",
    "        partial_ratio: Ratio of channels to apply ECA on. For example, 0.5 means only applying ECA on the first half of the channels.\n",
    "    \n",
    "    Returns:\n",
    "        The output tensor after applying ECA on the selected channels.\n",
    "    \"\"\"\n",
    "    # Get the shape of the input tensor\n",
    "    channels = input_tensor.shape[-1]\n",
    "    \n",
    "    # Calculate the number of channels to apply ECA on\n",
    "    partial_channels = int(channels * partial_ratio)\n",
    "    \n",
    "    # Split the input tensor into two parts: the first part to apply ECA and the second part to leave unchanged\n",
    "    eca_part = input_tensor[:, :, :, :partial_channels]\n",
    "    non_eca_part = input_tensor[:, :, :, partial_channels:]\n",
    "    \n",
    "    # Apply global average pooling to the selected channels\n",
    "    avg_pool = K.mean(eca_part, axis=[1, 2], keepdims=True)  # (batch_size, 1, 1, partial_channels)\n",
    "    \n",
    "    # Apply 1D convolution (as Conv2D with (k_size, 1) kernel) to capture cross-channel dependencies\n",
    "    conv = Conv2D(filters=partial_channels, kernel_size=(k_size, 1), padding='same', activation='sigmoid')(avg_pool)\n",
    "    \n",
    "    # Multiply the attention map with the input feature maps (only for the selected channels)\n",
    "    weighted_eca_part = Multiply()([eca_part, conv])  # (batch_size, height, width, partial_channels)\n",
    "    \n",
    "    # Concatenate the processed ECA part with the unchanged part\n",
    "    output = tf.concat([weighted_eca_part, non_eca_part], axis=-1)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Create MobileNet base model (or any other backbone)\n",
    "base_model = tf.keras.applications.MobileNet(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "feature_maps = base_model.output\n",
    "\n",
    "# Apply ECA only to a portion of the channels (50% of channels in this case)\n",
    "eca_feature_maps = eca_layer(feature_maps, k_size=5, partial_ratio=0.5)  # You can change the partial_ratio to adjust the number of channels\n",
    "\n",
    "# Add global average pooling\n",
    "x = GlobalAveragePooling2D()(eca_feature_maps)\n",
    "\n",
    "# Add fully connected layers\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "outputs = Dense(100, activation='softmax')(x)  # Adjust the number of classes as needed\n",
    "\n",
    "# Create the final model\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "metrics = [\n",
    "    tf.keras.metrics.CategoricalAccuracy(),\n",
    "    tf.keras.metrics.Precision(),\n",
    "    tf.keras.metrics.Recall(),\n",
    "]\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-27 18:31:03.745111: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-10-27 18:31:04.160116: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-10-27 18:31:05.492368: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f596d926db0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-10-27 18:31:05.492458: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2024-10-27 18:31:05.492474: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2024-10-27 18:31:05.527932: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730025065.800410    1638 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 34s 77ms/step - loss: 2.5897 - categorical_accuracy: 0.4371 - precision: 0.8907 - recall: 0.1787 - val_loss: 1.6635 - val_categorical_accuracy: 0.5732 - val_precision: 0.8683 - val_recall: 0.3161 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "176/176 [==============================] - 13s 72ms/step - loss: 0.9353 - categorical_accuracy: 0.7611 - precision: 0.9129 - recall: 0.6023 - val_loss: 0.8555 - val_categorical_accuracy: 0.7710 - val_precision: 0.8954 - val_recall: 0.6381 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "176/176 [==============================] - 13s 71ms/step - loss: 0.5859 - categorical_accuracy: 0.8397 - precision: 0.9254 - recall: 0.7519 - val_loss: 0.7390 - val_categorical_accuracy: 0.7908 - val_precision: 0.8705 - val_recall: 0.7138 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "176/176 [==============================] - 13s 73ms/step - loss: 0.4112 - categorical_accuracy: 0.8880 - precision: 0.9422 - recall: 0.8292 - val_loss: 0.5383 - val_categorical_accuracy: 0.8494 - val_precision: 0.9121 - val_recall: 0.7887 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "176/176 [==============================] - 13s 70ms/step - loss: 0.3008 - categorical_accuracy: 0.9193 - precision: 0.9549 - recall: 0.8784 - val_loss: 0.5064 - val_categorical_accuracy: 0.8526 - val_precision: 0.9069 - val_recall: 0.8093 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "176/176 [==============================] - 13s 70ms/step - loss: 0.2399 - categorical_accuracy: 0.9336 - precision: 0.9605 - recall: 0.9002 - val_loss: 0.4737 - val_categorical_accuracy: 0.8640 - val_precision: 0.9111 - val_recall: 0.8256 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "176/176 [==============================] - 13s 72ms/step - loss: 0.1832 - categorical_accuracy: 0.9512 - precision: 0.9700 - recall: 0.9259 - val_loss: 0.4580 - val_categorical_accuracy: 0.8651 - val_precision: 0.9076 - val_recall: 0.8374 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "176/176 [==============================] - 13s 71ms/step - loss: 0.1464 - categorical_accuracy: 0.9608 - precision: 0.9741 - recall: 0.9446 - val_loss: 0.4465 - val_categorical_accuracy: 0.8714 - val_precision: 0.9030 - val_recall: 0.8459 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "176/176 [==============================] - 14s 74ms/step - loss: 0.1217 - categorical_accuracy: 0.9682 - precision: 0.9792 - recall: 0.9549 - val_loss: 0.4273 - val_categorical_accuracy: 0.8793 - val_precision: 0.9131 - val_recall: 0.8548 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "176/176 [==============================] - 13s 71ms/step - loss: 0.1045 - categorical_accuracy: 0.9713 - precision: 0.9793 - recall: 0.9616 - val_loss: 0.4365 - val_categorical_accuracy: 0.8754 - val_precision: 0.9098 - val_recall: 0.8491 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "176/176 [==============================] - 14s 76ms/step - loss: 0.0851 - categorical_accuracy: 0.9792 - precision: 0.9838 - recall: 0.9719 - val_loss: 0.4124 - val_categorical_accuracy: 0.8842 - val_precision: 0.9142 - val_recall: 0.8668 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "176/176 [==============================] - 14s 76ms/step - loss: 0.0750 - categorical_accuracy: 0.9801 - precision: 0.9845 - recall: 0.9724 - val_loss: 0.4528 - val_categorical_accuracy: 0.8739 - val_precision: 0.9042 - val_recall: 0.8615 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "176/176 [==============================] - 13s 72ms/step - loss: 0.0710 - categorical_accuracy: 0.9814 - precision: 0.9841 - recall: 0.9761 - val_loss: 0.4350 - val_categorical_accuracy: 0.8757 - val_precision: 0.9038 - val_recall: 0.8608 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "176/176 [==============================] - 14s 76ms/step - loss: 0.0507 - categorical_accuracy: 0.9864 - precision: 0.9891 - recall: 0.9828 - val_loss: 0.3659 - val_categorical_accuracy: 0.8956 - val_precision: 0.9205 - val_recall: 0.8803 - lr: 5.0000e-05\n",
      "Epoch 15/50\n",
      "176/176 [==============================] - 13s 73ms/step - loss: 0.0400 - categorical_accuracy: 0.9900 - precision: 0.9915 - recall: 0.9880 - val_loss: 0.3485 - val_categorical_accuracy: 0.9006 - val_precision: 0.9257 - val_recall: 0.8888 - lr: 5.0000e-05\n",
      "Epoch 16/50\n",
      "176/176 [==============================] - 14s 76ms/step - loss: 0.0382 - categorical_accuracy: 0.9904 - precision: 0.9923 - recall: 0.9891 - val_loss: 0.3466 - val_categorical_accuracy: 0.9016 - val_precision: 0.9255 - val_recall: 0.8917 - lr: 5.0000e-05\n",
      "Epoch 17/50\n",
      "176/176 [==============================] - 13s 72ms/step - loss: 0.0346 - categorical_accuracy: 0.9909 - precision: 0.9916 - recall: 0.9900 - val_loss: 0.3473 - val_categorical_accuracy: 0.9027 - val_precision: 0.9242 - val_recall: 0.8881 - lr: 5.0000e-05\n",
      "Epoch 18/50\n",
      "176/176 [==============================] - 13s 70ms/step - loss: 0.0331 - categorical_accuracy: 0.9915 - precision: 0.9925 - recall: 0.9905 - val_loss: 0.3585 - val_categorical_accuracy: 0.9020 - val_precision: 0.9224 - val_recall: 0.8910 - lr: 5.0000e-05\n",
      "Epoch 19/50\n",
      "176/176 [==============================] - 13s 73ms/step - loss: 0.0282 - categorical_accuracy: 0.9940 - precision: 0.9941 - recall: 0.9930 - val_loss: 0.3482 - val_categorical_accuracy: 0.9013 - val_precision: 0.9232 - val_recall: 0.8917 - lr: 5.0000e-05\n",
      "Epoch 20/50\n",
      "176/176 [==============================] - 13s 72ms/step - loss: 0.0242 - categorical_accuracy: 0.9939 - precision: 0.9945 - recall: 0.9928 - val_loss: 0.3349 - val_categorical_accuracy: 0.9048 - val_precision: 0.9236 - val_recall: 0.8935 - lr: 2.5000e-05\n",
      "Epoch 21/50\n",
      "176/176 [==============================] - 13s 70ms/step - loss: 0.0223 - categorical_accuracy: 0.9933 - precision: 0.9937 - recall: 0.9931 - val_loss: 0.3377 - val_categorical_accuracy: 0.9055 - val_precision: 0.9274 - val_recall: 0.8981 - lr: 2.5000e-05\n",
      "Epoch 22/50\n",
      "176/176 [==============================] - 13s 70ms/step - loss: 0.0216 - categorical_accuracy: 0.9947 - precision: 0.9950 - recall: 0.9940 - val_loss: 0.3369 - val_categorical_accuracy: 0.9094 - val_precision: 0.9248 - val_recall: 0.8956 - lr: 2.5000e-05\n",
      "Epoch 23/50\n",
      "176/176 [==============================] - 13s 73ms/step - loss: 0.0207 - categorical_accuracy: 0.9948 - precision: 0.9949 - recall: 0.9946 - val_loss: 0.3465 - val_categorical_accuracy: 0.9006 - val_precision: 0.9229 - val_recall: 0.8924 - lr: 2.5000e-05\n",
      "Epoch 24/50\n",
      "176/176 [==============================] - 13s 73ms/step - loss: 0.0222 - categorical_accuracy: 0.9933 - precision: 0.9934 - recall: 0.9928 - val_loss: 0.3334 - val_categorical_accuracy: 0.9084 - val_precision: 0.9263 - val_recall: 0.8970 - lr: 2.5000e-05\n",
      "Epoch 25/50\n",
      "176/176 [==============================] - 13s 72ms/step - loss: 0.0188 - categorical_accuracy: 0.9952 - precision: 0.9953 - recall: 0.9948 - val_loss: 0.3321 - val_categorical_accuracy: 0.9073 - val_precision: 0.9260 - val_recall: 0.8977 - lr: 1.2500e-05\n",
      "Epoch 26/50\n",
      "176/176 [==============================] - 14s 75ms/step - loss: 0.0195 - categorical_accuracy: 0.9942 - precision: 0.9945 - recall: 0.9940 - val_loss: 0.3285 - val_categorical_accuracy: 0.9094 - val_precision: 0.9282 - val_recall: 0.8995 - lr: 1.2500e-05\n",
      "Epoch 27/50\n",
      "176/176 [==============================] - 13s 73ms/step - loss: 0.0175 - categorical_accuracy: 0.9954 - precision: 0.9956 - recall: 0.9950 - val_loss: 0.3316 - val_categorical_accuracy: 0.9087 - val_precision: 0.9278 - val_recall: 0.8988 - lr: 6.2500e-06\n",
      "Epoch 28/50\n",
      "176/176 [==============================] - 13s 73ms/step - loss: 0.0167 - categorical_accuracy: 0.9957 - precision: 0.9960 - recall: 0.9955 - val_loss: 0.3301 - val_categorical_accuracy: 0.9087 - val_precision: 0.9280 - val_recall: 0.8977 - lr: 6.2500e-06\n",
      "Epoch 29/50\n",
      "176/176 [==============================] - 13s 71ms/step - loss: 0.0158 - categorical_accuracy: 0.9963 - precision: 0.9964 - recall: 0.9957 - val_loss: 0.3291 - val_categorical_accuracy: 0.9094 - val_precision: 0.9282 - val_recall: 0.9002 - lr: 3.1250e-06\n",
      "Epoch 30/50\n",
      "176/176 [==============================] - 13s 71ms/step - loss: 0.0163 - categorical_accuracy: 0.9949 - precision: 0.9950 - recall: 0.9947 - val_loss: 0.3294 - val_categorical_accuracy: 0.9084 - val_precision: 0.9271 - val_recall: 0.8991 - lr: 3.1250e-06\n",
      "Epoch 31/50\n",
      "176/176 [==============================] - 14s 77ms/step - loss: 0.0155 - categorical_accuracy: 0.9954 - precision: 0.9955 - recall: 0.9949 - val_loss: 0.3285 - val_categorical_accuracy: 0.9077 - val_precision: 0.9271 - val_recall: 0.8984 - lr: 1.5625e-06\n",
      "Epoch 32/50\n",
      "176/176 [==============================] - 13s 74ms/step - loss: 0.0162 - categorical_accuracy: 0.9955 - precision: 0.9957 - recall: 0.9950 - val_loss: 0.3296 - val_categorical_accuracy: 0.9077 - val_precision: 0.9271 - val_recall: 0.8991 - lr: 1.5625e-06\n",
      "Epoch 33/50\n",
      "176/176 [==============================] - 13s 71ms/step - loss: 0.0160 - categorical_accuracy: 0.9954 - precision: 0.9956 - recall: 0.9950 - val_loss: 0.3289 - val_categorical_accuracy: 0.9080 - val_precision: 0.9275 - val_recall: 0.8995 - lr: 7.8125e-07\n",
      "Epoch 34/50\n",
      "176/176 [==============================] - 14s 75ms/step - loss: 0.0157 - categorical_accuracy: 0.9958 - precision: 0.9959 - recall: 0.9956 - val_loss: 0.3301 - val_categorical_accuracy: 0.9070 - val_precision: 0.9272 - val_recall: 0.8999 - lr: 7.8125e-07\n",
      "Epoch 35/50\n",
      "176/176 [==============================] - 14s 77ms/step - loss: 0.0150 - categorical_accuracy: 0.9956 - precision: 0.9958 - recall: 0.9955 - val_loss: 0.3295 - val_categorical_accuracy: 0.9077 - val_precision: 0.9265 - val_recall: 0.8995 - lr: 3.9062e-07\n",
      "Epoch 36/50\n",
      "176/176 [==============================] - 14s 77ms/step - loss: 0.0157 - categorical_accuracy: 0.9957 - precision: 0.9959 - recall: 0.9956 - val_loss: 0.3293 - val_categorical_accuracy: 0.9080 - val_precision: 0.9272 - val_recall: 0.9002 - lr: 3.9062e-07\n",
      "Epoch 37/50\n",
      "176/176 [==============================] - 14s 75ms/step - loss: 0.0161 - categorical_accuracy: 0.9951 - precision: 0.9955 - recall: 0.9948 - val_loss: 0.3295 - val_categorical_accuracy: 0.9080 - val_precision: 0.9268 - val_recall: 0.8991 - lr: 1.9531e-07\n",
      "Epoch 38/50\n",
      "176/176 [==============================] - 14s 77ms/step - loss: 0.0146 - categorical_accuracy: 0.9962 - precision: 0.9964 - recall: 0.9962 - val_loss: 0.3300 - val_categorical_accuracy: 0.9080 - val_precision: 0.9271 - val_recall: 0.8991 - lr: 1.9531e-07\n",
      "Epoch 39/50\n",
      "176/176 [==============================] - 14s 77ms/step - loss: 0.0162 - categorical_accuracy: 0.9952 - precision: 0.9956 - recall: 0.9949 - val_loss: 0.3294 - val_categorical_accuracy: 0.9073 - val_precision: 0.9261 - val_recall: 0.8995 - lr: 9.7656e-08\n",
      "Epoch 40/50\n",
      "176/176 [==============================] - 14s 75ms/step - loss: 0.0160 - categorical_accuracy: 0.9955 - precision: 0.9956 - recall: 0.9950 - val_loss: 0.3290 - val_categorical_accuracy: 0.9077 - val_precision: 0.9265 - val_recall: 0.8991 - lr: 9.7656e-08\n",
      "Epoch 41/50\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0146 - categorical_accuracy: 0.9963 - precision: 0.9965 - recall: 0.9959 - val_loss: 0.3297 - val_categorical_accuracy: 0.9084 - val_precision: 0.9268 - val_recall: 0.8995 - lr: 4.8828e-08\n",
      "Epoch 42/50\n",
      "176/176 [==============================] - 14s 75ms/step - loss: 0.0158 - categorical_accuracy: 0.9951 - precision: 0.9956 - recall: 0.9950 - val_loss: 0.3296 - val_categorical_accuracy: 0.9084 - val_precision: 0.9265 - val_recall: 0.8995 - lr: 4.8828e-08\n",
      "Epoch 43/50\n",
      "176/176 [==============================] - 14s 74ms/step - loss: 0.0153 - categorical_accuracy: 0.9956 - precision: 0.9958 - recall: 0.9954 - val_loss: 0.3302 - val_categorical_accuracy: 0.9080 - val_precision: 0.9261 - val_recall: 0.8995 - lr: 2.4414e-08\n",
      "Epoch 44/50\n",
      "176/176 [==============================] - 14s 76ms/step - loss: 0.0148 - categorical_accuracy: 0.9966 - precision: 0.9966 - recall: 0.9963 - val_loss: 0.3295 - val_categorical_accuracy: 0.9077 - val_precision: 0.9265 - val_recall: 0.8991 - lr: 2.4414e-08\n",
      "Epoch 45/50\n",
      "176/176 [==============================] - 14s 76ms/step - loss: 0.0152 - categorical_accuracy: 0.9960 - precision: 0.9962 - recall: 0.9957 - val_loss: 0.3294 - val_categorical_accuracy: 0.9080 - val_precision: 0.9268 - val_recall: 0.8999 - lr: 1.2207e-08\n",
      "Epoch 46/50\n",
      "176/176 [==============================] - 14s 76ms/step - loss: 0.0158 - categorical_accuracy: 0.9953 - precision: 0.9956 - recall: 0.9952 - val_loss: 0.3293 - val_categorical_accuracy: 0.9080 - val_precision: 0.9265 - val_recall: 0.8991 - lr: 1.2207e-08\n",
      "Epoch 47/50\n",
      "176/176 [==============================] - 14s 77ms/step - loss: 0.0154 - categorical_accuracy: 0.9951 - precision: 0.9955 - recall: 0.9950 - val_loss: 0.3298 - val_categorical_accuracy: 0.9080 - val_precision: 0.9265 - val_recall: 0.8995 - lr: 1.0000e-08\n",
      "Epoch 48/50\n",
      "176/176 [==============================] - 14s 75ms/step - loss: 0.0150 - categorical_accuracy: 0.9964 - precision: 0.9968 - recall: 0.9962 - val_loss: 0.3293 - val_categorical_accuracy: 0.9077 - val_precision: 0.9268 - val_recall: 0.8995 - lr: 1.0000e-08\n",
      "Epoch 49/50\n",
      "176/176 [==============================] - 13s 72ms/step - loss: 0.0156 - categorical_accuracy: 0.9958 - precision: 0.9959 - recall: 0.9952 - val_loss: 0.3295 - val_categorical_accuracy: 0.9080 - val_precision: 0.9271 - val_recall: 0.8991 - lr: 1.0000e-08\n",
      "Epoch 50/50\n",
      "176/176 [==============================] - 13s 71ms/step - loss: 0.0154 - categorical_accuracy: 0.9953 - precision: 0.9957 - recall: 0.9951 - val_loss: 0.3293 - val_categorical_accuracy: 0.9084 - val_precision: 0.9265 - val_recall: 0.8995 - lr: 1.0000e-08\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "log_dir = \"../Running result/0.5/0.5\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=2, min_lr=1e-8)\n",
    "\n",
    "history = model.fit(train_ds, epochs=EPOCHS, validation_data=vaild_ds, callbacks=[lr_scheduler, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training history saved to: ../Running result/0.5/0.5.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: ../Running result/0.5/0.5.h5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # Import Pandas library\n",
    "import os\n",
    "\n",
    "# Define save path\n",
    "model_dir = \"../Running result/0.5\"\n",
    "excel_file_path = os.path.join(model_dir, \"0.5.xlsx\")  # Path to save the Excel file\n",
    "model_file_path = os.path.join(model_dir, \"0.5.h5\")  # Path to save the model\n",
    "\n",
    "# Check if the save directory exists; create it if it does not\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "# Save training history to an Excel file\n",
    "history_df = pd.DataFrame(history.history)  \n",
    "history_df.to_excel(excel_file_path, index=False)\n",
    "print(f\"Training history saved to: {excel_file_path}\")\n",
    "\n",
    "# Save the model to the specified path\n",
    "model.save(model_file_path)\n",
    "print(f\"Model saved to: {model_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

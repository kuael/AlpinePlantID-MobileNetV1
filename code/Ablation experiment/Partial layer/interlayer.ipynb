{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  \n",
    "import numpy as np       \n",
    "import pandas as pd       \n",
    "from matplotlib import pyplot as plt   \n",
    "import seaborn as sns  \n",
    "import time          \n",
    "from tensorflow.keras.callbacks import History, ReduceLROnPlateau, TensorBoard       \n",
    "from tensorflow.keras import metrics          \n",
    "from sklearn.metrics import confusion_matrix          \n",
    "import pickle\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Reshape, multiply, add, Dense, Conv2D, GlobalMaxPooling2D, Activation\n",
    "from tensorflow.keras import backend as K\n",
    "import platform\n",
    "import os\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Multiply, Dense\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Multiply\n",
    "import platform\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Settings\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:  3.11.7\n",
      "TensorFlow version:  2.15.0\n",
      "Current working directory:  /root/.jupyter/张彤/消融实验\n",
      "Linux w3q2ulc9.vm 5.15.0-60-generic #66-Ubuntu SMP Fri Jan 20 14:29:49 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux\n",
      "Sun Oct 27 20:15:46 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        On  | 00000000:09:00.0 Off |                  Off |\n",
      "|  0%   26C    P2              54W / 450W |  22684MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 4090        On  | 00000000:0B:00.0 Off |                  Off |\n",
      "|  0%   26C    P8              11W / 450W |    394MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1515      C   /root/anaconda3/bin/python                22674MiB |\n",
      "|    1   N/A  N/A      1515      C   /root/anaconda3/bin/python                  384MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# System Information Print the Python version\n",
    "print(\"Python version: \", platform.python_version())\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "print(\"Current working directory: \", os.getcwd())\n",
    "!uname -a\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Settings\n",
    "EPOCHS = 50\n",
    "IMAGE_SIZE = (224, 224)\n",
    "IMAGE_PATH = \"../data\"\n",
    "LEARNING_RATE = 1e-4\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14080 files belonging to 100 classes.\n",
      "Using 11264 files for training.\n",
      "Found 14080 files belonging to 100 classes.\n",
      "Using 2816 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    IMAGE_PATH,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",    \n",
    "    seed=123,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "vaild_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    IMAGE_PATH,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Normalization\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "def normalize_image(image):\n",
    "    return (image - mean_tensor) / std_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "train_image_augment = tf.keras.Sequential([\n",
    "    tf.keras.layers.Rescaling(1 / 255.0),\n",
    "    tf.keras.layers.RandomRotation(factor=0.2),\n",
    "    tf.keras.layers.RandomFlip(),\n",
    "])\n",
    "\n",
    "valid_image_augment = tf.keras.Sequential([\n",
    "    tf.keras.layers.Rescaling(1 / 255.0),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Processing\n",
    "def process_train_input(images, labels):\n",
    "    return train_image_augment(images), labels\n",
    "\n",
    "def process_valid_input(images, labels):\n",
    "    return valid_image_augment(images), labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "def convert_types_and_encode(x, y):\n",
    "    y = tf.cast(y, tf.int32)  \n",
    "    y_one_hot = tf.one_hot(y, 100)  \n",
    "    return x, y_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Data Preprocessing\n",
    "train_ds = train_ds.map(convert_types_and_encode)\n",
    "train_ds = train_ds.map(process_train_input, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "vaild_ds = vaild_ds.map(convert_types_and_encode)\n",
    "vaild_ds = vaild_ds.map(process_valid_input, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "vaild_ds = vaild_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Functional model inputs must come from `tf.keras.Input` (thus holding past layer metadata). They cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"model_1\" was not an Input tensor, it was generated by layer \"input_2\".\n",
      "Note that input tensors are instantiated via `tensor = tf.keras.Input(shape)`.\n",
      "The tensor that caused the issue was: KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D, Multiply, Dense\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# Define the modified ECA layer, which now supports partial channel selection\n",
    "def eca_layer(input_tensor, k_size=3, partial_ratio=0.25):\n",
    "    \"\"\"Efficient Channel Attention (ECA) for a portion of the channels.\n",
    "    \n",
    "    Args:\n",
    "        input_tensor: The input feature map (batch_size, height, width, channels).\n",
    "        k_size: Kernel size for the 1D convolution used in ECA.\n",
    "        partial_ratio: Ratio of channels to apply ECA on. In this case, 0.25 means applying ECA on 25% of the channels.\n",
    "    \n",
    "    Returns:\n",
    "        The output tensor after applying ECA on the selected channels.\n",
    "    \"\"\"\n",
    "    channels = input_tensor.shape[-1]  # Get the total number of channels\n",
    "    partial_channels = int(channels * partial_ratio)  # Calculate the number of channels to apply ECA\n",
    "\n",
    "    # Split the input tensor into two parts: the first part to apply ECA and the second part to leave unchanged\n",
    "    eca_part = input_tensor[:, :, :, :partial_channels]\n",
    "    non_eca_part = input_tensor[:, :, :, partial_channels:]\n",
    "    \n",
    "    # Apply global average pooling to the selected channels\n",
    "    avg_pool = tf.reduce_mean(eca_part, axis=[1, 2], keepdims=True)  # (batch_size, 1, 1, partial_channels)\n",
    "    \n",
    "    # Apply 1D convolution (as Conv2D with (k_size, 1) kernel) to capture cross-channel dependencies\n",
    "    conv = Conv2D(filters=partial_channels, kernel_size=(k_size, 1), padding='same', activation='sigmoid')(avg_pool)\n",
    "    \n",
    "    # Multiply the attention map with the input feature maps (only for the selected channels)\n",
    "    weighted_eca_part = Multiply()([eca_part, conv])  # (batch_size, height, width, partial_channels)\n",
    "    \n",
    "    # Concatenate the processed ECA part with the unchanged part\n",
    "    output = tf.concat([weighted_eca_part, non_eca_part], axis=-1)\n",
    "\n",
    "    return output\n",
    "\n",
    "# Create MobileNet base model (or any other backbone)\n",
    "base_model = tf.keras.applications.MobileNet(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "\n",
    "# Select the high-level layers to apply ECA\n",
    "# For high-level features, we can apply ECA to layers like 'conv_pw_11_relu', 'conv_pw_13_relu'\n",
    "selected_layers = ['conv_pw_11_relu', 'conv_pw_13_relu']  # Example high-level layers, you can modify based on your needs\n",
    "\n",
    "# Apply ECA only to the selected layers (high-level features)\n",
    "x = base_model.input\n",
    "for layer in base_model.layers:\n",
    "    x = layer(x)\n",
    "    if layer.name in selected_layers:\n",
    "        x = eca_layer(x, k_size=5, partial_ratio=0.75)  # Apply ECA to the selected high-level layers with 75% channels\n",
    "\n",
    "# Add global average pooling\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add fully connected layers\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "outputs = Dense(100, activation='softmax')(x)  # Adjust the number of classes as needed\n",
    "\n",
    "# Create the final model\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "metrics = [\n",
    "    tf.keras.metrics.CategoricalAccuracy(),\n",
    "    tf.keras.metrics.Precision(),\n",
    "    tf.keras.metrics.Recall(),\n",
    "]\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-27 20:16:03.479117: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-10-27 20:16:03.685528: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-10-27 20:16:04.780297: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f5b0caa87b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-10-27 20:16:04.780372: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2024-10-27 20:16:04.780388: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2024-10-27 20:16:04.812337: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730031365.056660    1641 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 34s 85ms/step - loss: 2.5931 - categorical_accuracy: 0.4414 - precision_1: 0.8945 - recall_1: 0.1800 - val_loss: 1.9312 - val_categorical_accuracy: 0.5650 - val_precision_1: 0.9076 - val_recall_1: 0.2127 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "176/176 [==============================] - 14s 76ms/step - loss: 0.9242 - categorical_accuracy: 0.7571 - precision_1: 0.9049 - recall_1: 0.6119 - val_loss: 0.8081 - val_categorical_accuracy: 0.7844 - val_precision_1: 0.9099 - val_recall_1: 0.6634 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "176/176 [==============================] - 14s 76ms/step - loss: 0.5614 - categorical_accuracy: 0.8433 - precision_1: 0.9263 - recall_1: 0.7602 - val_loss: 0.6665 - val_categorical_accuracy: 0.8026 - val_precision_1: 0.8906 - val_recall_1: 0.7340 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "176/176 [==============================] - 14s 79ms/step - loss: 0.3975 - categorical_accuracy: 0.8880 - precision_1: 0.9433 - recall_1: 0.8330 - val_loss: 0.5617 - val_categorical_accuracy: 0.8395 - val_precision_1: 0.9052 - val_recall_1: 0.7798 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "176/176 [==============================] - 14s 79ms/step - loss: 0.2921 - categorical_accuracy: 0.9204 - precision_1: 0.9553 - recall_1: 0.8809 - val_loss: 0.4916 - val_categorical_accuracy: 0.8608 - val_precision_1: 0.9097 - val_recall_1: 0.8054 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.2298 - categorical_accuracy: 0.9370 - precision_1: 0.9603 - recall_1: 0.9052 - val_loss: 0.4716 - val_categorical_accuracy: 0.8675 - val_precision_1: 0.9142 - val_recall_1: 0.8363 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "176/176 [==============================] - 14s 79ms/step - loss: 0.1707 - categorical_accuracy: 0.9533 - precision_1: 0.9688 - recall_1: 0.9331 - val_loss: 0.4492 - val_categorical_accuracy: 0.8675 - val_precision_1: 0.9052 - val_recall_1: 0.8374 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.1370 - categorical_accuracy: 0.9633 - precision_1: 0.9769 - recall_1: 0.9480 - val_loss: 0.4924 - val_categorical_accuracy: 0.8658 - val_precision_1: 0.8938 - val_recall_1: 0.8430 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "176/176 [==============================] - 14s 75ms/step - loss: 0.1004 - categorical_accuracy: 0.9740 - precision_1: 0.9819 - recall_1: 0.9642 - val_loss: 0.3795 - val_categorical_accuracy: 0.8910 - val_precision_1: 0.9231 - val_recall_1: 0.8654 - lr: 5.0000e-05\n",
      "Epoch 10/50\n",
      "176/176 [==============================] - 14s 77ms/step - loss: 0.0810 - categorical_accuracy: 0.9808 - precision_1: 0.9855 - recall_1: 0.9718 - val_loss: 0.3741 - val_categorical_accuracy: 0.8974 - val_precision_1: 0.9257 - val_recall_1: 0.8722 - lr: 5.0000e-05\n",
      "Epoch 11/50\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0702 - categorical_accuracy: 0.9843 - precision_1: 0.9888 - recall_1: 0.9773 - val_loss: 0.3910 - val_categorical_accuracy: 0.8899 - val_precision_1: 0.9236 - val_recall_1: 0.8714 - lr: 5.0000e-05\n",
      "Epoch 12/50\n",
      "176/176 [==============================] - 14s 76ms/step - loss: 0.0613 - categorical_accuracy: 0.9874 - precision_1: 0.9896 - recall_1: 0.9811 - val_loss: 0.3598 - val_categorical_accuracy: 0.8988 - val_precision_1: 0.9286 - val_recall_1: 0.8825 - lr: 5.0000e-05\n",
      "Epoch 13/50\n",
      "176/176 [==============================] - 14s 75ms/step - loss: 0.0562 - categorical_accuracy: 0.9881 - precision_1: 0.9904 - recall_1: 0.9837 - val_loss: 0.3645 - val_categorical_accuracy: 0.8984 - val_precision_1: 0.9265 - val_recall_1: 0.8814 - lr: 5.0000e-05\n",
      "Epoch 14/50\n",
      "176/176 [==============================] - 13s 72ms/step - loss: 0.0531 - categorical_accuracy: 0.9873 - precision_1: 0.9893 - recall_1: 0.9836 - val_loss: 0.3578 - val_categorical_accuracy: 0.8970 - val_precision_1: 0.9264 - val_recall_1: 0.8807 - lr: 5.0000e-05\n",
      "Epoch 15/50\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0451 - categorical_accuracy: 0.9894 - precision_1: 0.9917 - recall_1: 0.9871 - val_loss: 0.3623 - val_categorical_accuracy: 0.8984 - val_precision_1: 0.9232 - val_recall_1: 0.8842 - lr: 2.5000e-05\n",
      "Epoch 16/50\n",
      "176/176 [==============================] - 15s 80ms/step - loss: 0.0405 - categorical_accuracy: 0.9909 - precision_1: 0.9923 - recall_1: 0.9890 - val_loss: 0.3550 - val_categorical_accuracy: 0.9006 - val_precision_1: 0.9274 - val_recall_1: 0.8885 - lr: 2.5000e-05\n",
      "Epoch 17/50\n",
      "176/176 [==============================] - 14s 77ms/step - loss: 0.0385 - categorical_accuracy: 0.9911 - precision_1: 0.9930 - recall_1: 0.9897 - val_loss: 0.3450 - val_categorical_accuracy: 0.9045 - val_precision_1: 0.9285 - val_recall_1: 0.8896 - lr: 2.5000e-05\n",
      "Epoch 18/50\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0355 - categorical_accuracy: 0.9933 - precision_1: 0.9941 - recall_1: 0.9910 - val_loss: 0.3473 - val_categorical_accuracy: 0.9055 - val_precision_1: 0.9275 - val_recall_1: 0.8910 - lr: 2.5000e-05\n",
      "Epoch 19/50\n",
      "176/176 [==============================] - 14s 79ms/step - loss: 0.0341 - categorical_accuracy: 0.9924 - precision_1: 0.9934 - recall_1: 0.9912 - val_loss: 0.3455 - val_categorical_accuracy: 0.9038 - val_precision_1: 0.9292 - val_recall_1: 0.8906 - lr: 2.5000e-05\n",
      "Epoch 20/50\n",
      "176/176 [==============================] - 14s 74ms/step - loss: 0.0334 - categorical_accuracy: 0.9922 - precision_1: 0.9930 - recall_1: 0.9905 - val_loss: 0.3551 - val_categorical_accuracy: 0.9006 - val_precision_1: 0.9289 - val_recall_1: 0.8906 - lr: 2.5000e-05\n",
      "Epoch 21/50\n",
      "176/176 [==============================] - 14s 77ms/step - loss: 0.0292 - categorical_accuracy: 0.9942 - precision_1: 0.9948 - recall_1: 0.9932 - val_loss: 0.3395 - val_categorical_accuracy: 0.9034 - val_precision_1: 0.9283 - val_recall_1: 0.8913 - lr: 1.2500e-05\n",
      "Epoch 22/50\n",
      "176/176 [==============================] - 15s 80ms/step - loss: 0.0291 - categorical_accuracy: 0.9932 - precision_1: 0.9936 - recall_1: 0.9923 - val_loss: 0.3419 - val_categorical_accuracy: 0.9031 - val_precision_1: 0.9252 - val_recall_1: 0.8920 - lr: 1.2500e-05\n",
      "Epoch 23/50\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0258 - categorical_accuracy: 0.9947 - precision_1: 0.9948 - recall_1: 0.9941 - val_loss: 0.3376 - val_categorical_accuracy: 0.9070 - val_precision_1: 0.9282 - val_recall_1: 0.8956 - lr: 6.2500e-06\n",
      "Epoch 24/50\n",
      "176/176 [==============================] - 14s 77ms/step - loss: 0.0267 - categorical_accuracy: 0.9937 - precision_1: 0.9940 - recall_1: 0.9927 - val_loss: 0.3385 - val_categorical_accuracy: 0.9052 - val_precision_1: 0.9289 - val_recall_1: 0.8952 - lr: 6.2500e-06\n",
      "Epoch 25/50\n",
      "176/176 [==============================] - 14s 79ms/step - loss: 0.0258 - categorical_accuracy: 0.9941 - precision_1: 0.9945 - recall_1: 0.9930 - val_loss: 0.3372 - val_categorical_accuracy: 0.9045 - val_precision_1: 0.9289 - val_recall_1: 0.8949 - lr: 6.2500e-06\n",
      "Epoch 26/50\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0256 - categorical_accuracy: 0.9942 - precision_1: 0.9948 - recall_1: 0.9935 - val_loss: 0.3332 - val_categorical_accuracy: 0.9055 - val_precision_1: 0.9292 - val_recall_1: 0.8952 - lr: 3.1250e-06\n",
      "Epoch 27/50\n",
      "176/176 [==============================] - 15s 80ms/step - loss: 0.0244 - categorical_accuracy: 0.9943 - precision_1: 0.9948 - recall_1: 0.9938 - val_loss: 0.3348 - val_categorical_accuracy: 0.9055 - val_precision_1: 0.9298 - val_recall_1: 0.8942 - lr: 3.1250e-06\n",
      "Epoch 28/50\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0255 - categorical_accuracy: 0.9940 - precision_1: 0.9945 - recall_1: 0.9929 - val_loss: 0.3354 - val_categorical_accuracy: 0.9027 - val_precision_1: 0.9294 - val_recall_1: 0.8931 - lr: 1.5625e-06\n",
      "Epoch 29/50\n",
      "176/176 [==============================] - 14s 75ms/step - loss: 0.0226 - categorical_accuracy: 0.9950 - precision_1: 0.9953 - recall_1: 0.9946 - val_loss: 0.3358 - val_categorical_accuracy: 0.9052 - val_precision_1: 0.9294 - val_recall_1: 0.8931 - lr: 1.5625e-06\n",
      "Epoch 30/50\n",
      "176/176 [==============================] - 14s 79ms/step - loss: 0.0231 - categorical_accuracy: 0.9950 - precision_1: 0.9954 - recall_1: 0.9938 - val_loss: 0.3352 - val_categorical_accuracy: 0.9041 - val_precision_1: 0.9302 - val_recall_1: 0.8938 - lr: 7.8125e-07\n",
      "Epoch 31/50\n",
      "176/176 [==============================] - 14s 79ms/step - loss: 0.0239 - categorical_accuracy: 0.9944 - precision_1: 0.9947 - recall_1: 0.9938 - val_loss: 0.3350 - val_categorical_accuracy: 0.9052 - val_precision_1: 0.9302 - val_recall_1: 0.8938 - lr: 7.8125e-07\n",
      "Epoch 32/50\n",
      "176/176 [==============================] - 15s 80ms/step - loss: 0.0227 - categorical_accuracy: 0.9954 - precision_1: 0.9956 - recall_1: 0.9946 - val_loss: 0.3360 - val_categorical_accuracy: 0.9048 - val_precision_1: 0.9302 - val_recall_1: 0.8945 - lr: 3.9062e-07\n",
      "Epoch 33/50\n",
      "176/176 [==============================] - 15s 82ms/step - loss: 0.0238 - categorical_accuracy: 0.9946 - precision_1: 0.9948 - recall_1: 0.9940 - val_loss: 0.3359 - val_categorical_accuracy: 0.9055 - val_precision_1: 0.9295 - val_recall_1: 0.8942 - lr: 3.9062e-07\n",
      "Epoch 34/50\n",
      "176/176 [==============================] - 15s 80ms/step - loss: 0.0231 - categorical_accuracy: 0.9958 - precision_1: 0.9963 - recall_1: 0.9952 - val_loss: 0.3359 - val_categorical_accuracy: 0.9062 - val_precision_1: 0.9292 - val_recall_1: 0.8945 - lr: 1.9531e-07\n",
      "Epoch 35/50\n",
      "176/176 [==============================] - 14s 75ms/step - loss: 0.0228 - categorical_accuracy: 0.9955 - precision_1: 0.9959 - recall_1: 0.9949 - val_loss: 0.3357 - val_categorical_accuracy: 0.9059 - val_precision_1: 0.9292 - val_recall_1: 0.8942 - lr: 1.9531e-07\n",
      "Epoch 36/50\n",
      "176/176 [==============================] - 13s 73ms/step - loss: 0.0233 - categorical_accuracy: 0.9947 - precision_1: 0.9952 - recall_1: 0.9942 - val_loss: 0.3354 - val_categorical_accuracy: 0.9066 - val_precision_1: 0.9288 - val_recall_1: 0.8938 - lr: 9.7656e-08\n",
      "Epoch 37/50\n",
      "176/176 [==============================] - 13s 70ms/step - loss: 0.0231 - categorical_accuracy: 0.9955 - precision_1: 0.9956 - recall_1: 0.9949 - val_loss: 0.3357 - val_categorical_accuracy: 0.9066 - val_precision_1: 0.9292 - val_recall_1: 0.8949 - lr: 9.7656e-08\n",
      "Epoch 38/50\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0224 - categorical_accuracy: 0.9948 - precision_1: 0.9950 - recall_1: 0.9943 - val_loss: 0.3360 - val_categorical_accuracy: 0.9062 - val_precision_1: 0.9292 - val_recall_1: 0.8942 - lr: 4.8828e-08\n",
      "Epoch 39/50\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0238 - categorical_accuracy: 0.9951 - precision_1: 0.9952 - recall_1: 0.9944 - val_loss: 0.3358 - val_categorical_accuracy: 0.9059 - val_precision_1: 0.9302 - val_recall_1: 0.8945 - lr: 4.8828e-08\n",
      "Epoch 40/50\n",
      "176/176 [==============================] - 15s 81ms/step - loss: 0.0243 - categorical_accuracy: 0.9942 - precision_1: 0.9947 - recall_1: 0.9936 - val_loss: 0.3358 - val_categorical_accuracy: 0.9066 - val_precision_1: 0.9298 - val_recall_1: 0.8938 - lr: 2.4414e-08\n",
      "Epoch 41/50\n",
      "176/176 [==============================] - 14s 78ms/step - loss: 0.0235 - categorical_accuracy: 0.9950 - precision_1: 0.9956 - recall_1: 0.9945 - val_loss: 0.3358 - val_categorical_accuracy: 0.9062 - val_precision_1: 0.9302 - val_recall_1: 0.8942 - lr: 2.4414e-08\n",
      "Epoch 42/50\n",
      "176/176 [==============================] - 15s 80ms/step - loss: 0.0223 - categorical_accuracy: 0.9952 - precision_1: 0.9955 - recall_1: 0.9950 - val_loss: 0.3362 - val_categorical_accuracy: 0.9066 - val_precision_1: 0.9298 - val_recall_1: 0.8942 - lr: 1.2207e-08\n",
      "Epoch 43/50\n",
      "176/176 [==============================] - 15s 80ms/step - loss: 0.0225 - categorical_accuracy: 0.9954 - precision_1: 0.9958 - recall_1: 0.9944 - val_loss: 0.3366 - val_categorical_accuracy: 0.9062 - val_precision_1: 0.9291 - val_recall_1: 0.8938 - lr: 1.2207e-08\n",
      "Epoch 44/50\n",
      "176/176 [==============================] - 15s 81ms/step - loss: 0.0222 - categorical_accuracy: 0.9958 - precision_1: 0.9960 - recall_1: 0.9949 - val_loss: 0.3361 - val_categorical_accuracy: 0.9055 - val_precision_1: 0.9298 - val_recall_1: 0.8935 - lr: 1.0000e-08\n",
      "Epoch 45/50\n",
      "176/176 [==============================] - 15s 81ms/step - loss: 0.0229 - categorical_accuracy: 0.9951 - precision_1: 0.9953 - recall_1: 0.9946 - val_loss: 0.3357 - val_categorical_accuracy: 0.9073 - val_precision_1: 0.9298 - val_recall_1: 0.8942 - lr: 1.0000e-08\n",
      "Epoch 46/50\n",
      "176/176 [==============================] - 15s 80ms/step - loss: 0.0230 - categorical_accuracy: 0.9952 - precision_1: 0.9957 - recall_1: 0.9946 - val_loss: 0.3357 - val_categorical_accuracy: 0.9062 - val_precision_1: 0.9302 - val_recall_1: 0.8942 - lr: 1.0000e-08\n",
      "Epoch 47/50\n",
      "176/176 [==============================] - 15s 80ms/step - loss: 0.0226 - categorical_accuracy: 0.9954 - precision_1: 0.9957 - recall_1: 0.9945 - val_loss: 0.3360 - val_categorical_accuracy: 0.9066 - val_precision_1: 0.9298 - val_recall_1: 0.8938 - lr: 1.0000e-08\n",
      "Epoch 48/50\n",
      "176/176 [==============================] - 15s 80ms/step - loss: 0.0242 - categorical_accuracy: 0.9947 - precision_1: 0.9951 - recall_1: 0.9939 - val_loss: 0.3356 - val_categorical_accuracy: 0.9062 - val_precision_1: 0.9295 - val_recall_1: 0.8945 - lr: 1.0000e-08\n",
      "Epoch 49/50\n",
      "176/176 [==============================] - 14s 79ms/step - loss: 0.0233 - categorical_accuracy: 0.9949 - precision_1: 0.9956 - recall_1: 0.9945 - val_loss: 0.3360 - val_categorical_accuracy: 0.9070 - val_precision_1: 0.9292 - val_recall_1: 0.8942 - lr: 1.0000e-08\n",
      "Epoch 50/50\n",
      "176/176 [==============================] - 15s 81ms/step - loss: 0.0232 - categorical_accuracy: 0.9945 - precision_1: 0.9949 - recall_1: 0.9936 - val_loss: 0.3362 - val_categorical_accuracy: 0.9062 - val_precision_1: 0.9298 - val_recall_1: 0.8938 - lr: 1.0000e-08\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "log_dir = \"../Running result/interlayer/interlayer\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=2, min_lr=1e-8)\n",
    "\n",
    "history = model.fit(train_ds, epochs=EPOCHS, validation_data=vaild_ds, callbacks=[lr_scheduler, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training history saved to: ../Running result/interlayer/interlayer/interlayer.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: ../Running result/interlayer/interlayer/interlayer.h5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # Import the Pandas library\n",
    "import os\n",
    "\n",
    "# Define save paths\n",
    "model_dir = \"../Running result/interlayer/interlayer\"\n",
    "excel_file_path = os.path.join(model_dir, \"interlayer.xlsx\")  # Path to save the Excel file\n",
    "model_file_path = os.path.join(model_dir, \"interlayer.h5\")  # Path to save the model\n",
    "\n",
    "# Check if the save directory exists, and create it if it does not\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "# Save training history to an Excel file\n",
    "history_df = pd.DataFrame(history.history)  \n",
    "history_df.to_excel(excel_file_path, index=False)\n",
    "print(f\"Training history saved to: {excel_file_path}\")\n",
    "\n",
    "# Save the model to the specified path\n",
    "model.save(model_file_path)\n",
    "print(f\"Model saved to: {model_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

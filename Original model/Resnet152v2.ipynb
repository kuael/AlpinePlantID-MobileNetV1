{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 7461,
     "status": "ok",
     "timestamp": 1712712445711,
     "user": {
      "displayName": "zai wang",
      "userId": "09044436193906041350"
     },
     "user_tz": -480
    },
    "id": "xdUwGvcgizAu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import time\n",
    "from tensorflow.keras.callbacks import History\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, TensorBoard\n",
    "from tensorflow.keras import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import TensorBoard\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1712712445712,
     "user": {
      "displayName": "zai wang",
      "userId": "09044436193906041350"
     },
     "user_tz": -480
    },
    "id": "7_ue8L4L2ga8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1712712445712,
     "user": {
      "displayName": "zai wang",
      "userId": "09044436193906041350"
     },
     "user_tz": -480
    },
    "id": "5DXQYT4XxsVR",
    "outputId": "9aad8e14-7555-468e-ad24-4db7c8c4b9ce",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.15.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1712712445712,
     "user": {
      "displayName": "zai wang",
      "userId": "09044436193906041350"
     },
     "user_tz": -480
    },
    "id": "xV9Km_bExvQ6",
    "outputId": "d499128b-5878-4202-e1c6-4e5dcc95f4c9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:  3.11.7\n",
      "TensorFlow version:  2.15.0\n",
      "Current working directory:  /root/.jupyter/张彤/模型\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import platform\n",
    "import tensorflow as tf\n",
    "\n",
    "# Print Python version\n",
    "print(\"Python version: \", platform.python_version())\n",
    "\n",
    "# Print the TensorFlow version\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "\n",
    "# Print the current working directory\n",
    "import os\n",
    "print(\"Current working directory: \", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1712712445712,
     "user": {
      "displayName": "zai wang",
      "userId": "09044436193906041350"
     },
     "user_tz": -480
    },
    "id": "NN5gdfIdxvTE",
    "outputId": "4c4c5930-61ec-4c89-e6bc-28d1320d82b1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linux w3q2ulc9.vm 5.15.0-60-generic #66-Ubuntu SMP Fri Jan 20 14:29:49 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux\n"
     ]
    }
   ],
   "source": [
    "# View Linux system information This command is used in Linux to obtain the system kernel and other information. Executing this command returns detailed information about the operating system, including the kernel version, system architecture, and so on.\n",
    "!uname -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1712712445712,
     "user": {
      "displayName": "zai wang",
      "userId": "09044436193906041350"
     },
     "user_tz": -480
    },
    "id": "bV46_YAKxvVS",
    "outputId": "33cb7888-e932-4fa5-944e-41f8aecb9bc4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Oct 26 10:52:30 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        On  | 00000000:09:00.0 Off |                  Off |\n",
      "|  0%   27C    P8              10W / 450W |      3MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 4090        On  | 00000000:0B:00.0 Off |                  Off |\n",
      "|  0%   28C    P8               4W / 450W |      3MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1712712445712,
     "user": {
      "displayName": "zai wang",
      "userId": "09044436193906041350"
     },
     "user_tz": -480
    },
    "id": "shj8o-0zizAu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "IMAGE_SIZE = (224,224)\n",
    "IMAGE_PATH = \"../data\"\n",
    "LEARNING_RATE = 1e-4\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3407,
     "status": "ok",
     "timestamp": 1712712449115,
     "user": {
      "displayName": "zai wang",
      "userId": "09044436193906041350"
     },
     "user_tz": -480
    },
    "id": "d41g-7x9izAv",
    "outputId": "d4f8f6c2-1695-4afa-e730-5bd3e2bc1e80",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14080 files belonging to 100 classes.\n",
      "Using 11264 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 10:52:33.203247: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-26 10:52:33.203595: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-26 10:52:33.320421: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-26 10:52:33.320736: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-26 10:52:33.320910: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-26 10:52:33.321071: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-26 10:52:33.494716: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-26 10:52:33.495007: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-26 10:52:33.495177: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-26 10:52:33.495329: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-26 10:52:33.495483: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-26 10:52:33.495634: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-26 10:52:33.511302: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-26 10:52:33.511559: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-26 10:52:33.511742: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-26 10:52:33.511912: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-26 10:52:33.512082: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-26 10:52:33.512214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22287 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:09:00.0, compute capability: 8.9\n",
      "2024-10-26 10:52:33.512999: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-26 10:52:33.513155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22287 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:0b:00.0, compute capability: 8.9\n",
      "2024-10-26 10:52:34.193933: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    IMAGE_PATH,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 454,
     "status": "ok",
     "timestamp": 1712712449567,
     "user": {
      "displayName": "zai wang",
      "userId": "09044436193906041350"
     },
     "user_tz": -480
    },
    "id": "1peCTdVKizAv",
    "outputId": "4b97beab-3ab2-4ffb-e638-b35e07a29450",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14080 files belonging to 100 classes.\n",
      "Using 2816 files for validation.\n"
     ]
    }
   ],
   "source": [
    "vaild_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    IMAGE_PATH,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1712712449567,
     "user": {
      "displayName": "zai wang",
      "userId": "09044436193906041350"
     },
     "user_tz": -480
    },
    "id": "u1GQEVKQizAv",
    "outputId": "7a85ac03-3ede-4a0e-bd50-571555b9a4ac",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '10',\n",
       " '100',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '2',\n",
       " '20',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '3',\n",
       " '30',\n",
       " '31',\n",
       " '32',\n",
       " '33',\n",
       " '34',\n",
       " '35',\n",
       " '36',\n",
       " '37',\n",
       " '38',\n",
       " '39',\n",
       " '4',\n",
       " '40',\n",
       " '41',\n",
       " '42',\n",
       " '43',\n",
       " '44',\n",
       " '45',\n",
       " '46',\n",
       " '47',\n",
       " '48',\n",
       " '49',\n",
       " '5',\n",
       " '50',\n",
       " '51',\n",
       " '52',\n",
       " '53',\n",
       " '54',\n",
       " '55',\n",
       " '56',\n",
       " '57',\n",
       " '58',\n",
       " '59',\n",
       " '6',\n",
       " '60',\n",
       " '61',\n",
       " '62',\n",
       " '63',\n",
       " '64',\n",
       " '65',\n",
       " '66',\n",
       " '67',\n",
       " '68',\n",
       " '69',\n",
       " '7',\n",
       " '70',\n",
       " '71',\n",
       " '72',\n",
       " '73',\n",
       " '74',\n",
       " '75',\n",
       " '76',\n",
       " '77',\n",
       " '78',\n",
       " '79',\n",
       " '8',\n",
       " '80',\n",
       " '81',\n",
       " '82',\n",
       " '83',\n",
       " '84',\n",
       " '85',\n",
       " '86',\n",
       " '87',\n",
       " '88',\n",
       " '89',\n",
       " '9',\n",
       " '90',\n",
       " '91',\n",
       " '92',\n",
       " '93',\n",
       " '94',\n",
       " '95',\n",
       " '96',\n",
       " '97',\n",
       " '98',\n",
       " '99']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1712712449567,
     "user": {
      "displayName": "zai wang",
      "userId": "09044436193906041350"
     },
     "user_tz": -480
    },
    "id": "hG6IP8fqXHHZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the mean and standard deviation\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Convert the mean and standard deviation to TensorFlow tensors\n",
    "mean_tensor = tf.constant(mean, dtype=tf.float32)\n",
    "std_tensor = tf.constant(std, dtype=tf.float32)\n",
    "\n",
    "# Define a function to perform a standardized operation\n",
    "def normalize_image(image):\n",
    "    return (image - mean_tensor) / std_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1712712449567,
     "user": {
      "displayName": "zai wang",
      "userId": "09044436193906041350"
     },
     "user_tz": -480
    },
    "id": "ggGEcEM1izAv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Image enhancement definition\n",
    "train_image_augment = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Rescaling(1 / 255.0), # normalization\n",
    "        tf.keras.layers.RandomRotation(factor=0.2), # Random rotation\n",
    "        tf.keras.layers.RandomFlip(), # Random flip\n",
    "    ]\n",
    ")\n",
    "\n",
    "valid_image_augment = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Rescaling(1 / 255.0), # normalization\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1712712449567,
     "user": {
      "displayName": "zai wang",
      "userId": "09044436193906041350"
     },
     "user_tz": -480
    },
    "id": "rYPdvx1HizAv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input processing method\n",
    "def process_train_input(images, labels):\n",
    "    return train_image_augment(images), labels\n",
    "\n",
    "def process_valid_input(images, labels):\n",
    "    return valid_image_augment(images), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1712712449567,
     "user": {
      "displayName": "zai wang",
      "userId": "09044436193906041350"
     },
     "user_tz": -480
    },
    "id": "6RM_egVMizAv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# one-hot encoding and type conversion\n",
    "def convert_types_and_encode(x, y):\n",
    "    y = tf.cast(y, tf.int32)  # Convert the label type to an integer\n",
    "    y_one_hot = tf.one_hot(y, 100)  # Apply one-hot encoding\n",
    "    return x, y_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 849,
     "status": "ok",
     "timestamp": 1712712450414,
     "user": {
      "displayName": "zai wang",
      "userId": "09044436193906041350"
     },
     "user_tz": -480
    },
    "id": "7EARAqH4izAw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply data set preprocessing\n",
    "train_ds = train_ds.map(convert_types_and_encode) # Convert data types and encodings\n",
    "train_ds = train_ds.map(process_train_input, num_parallel_calls=tf.data.AUTOTUNE) # Application enhancement\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE) # Optimized loading\n",
    "\n",
    "vaild_ds = vaild_ds.map(convert_types_and_encode) # Convert data types and encodings\n",
    "vaild_ds = vaild_ds.map(process_valid_input, num_parallel_calls=tf.data.AUTOTUNE) # Application enhancement\n",
    "vaild_ds = vaild_ds.prefetch(tf.data.AUTOTUNE) # Optimized loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7824,
     "status": "ok",
     "timestamp": 1712712458235,
     "user": {
      "displayName": "zai wang",
      "userId": "09044436193906041350"
     },
     "user_tz": -480
    },
    "id": "4h7_0_DqizAw",
    "outputId": "fb344434-3f42-468d-8ca1-65763ff68d71",
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.ResNet152V2(include_top=True,weights='imagenet',input_shape=(*IMAGE_SIZE,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1712712458236,
     "user": {
      "displayName": "zai wang",
      "userId": "09044436193906041350"
     },
     "user_tz": -480
    },
    "id": "WJYpyPiySX5g",
    "outputId": "a4a2098e-7a6a-4c1a-fd15-d242ff8332c1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1\n",
      "conv1_pad\n",
      "conv1_conv\n",
      "pool1_pad\n",
      "pool1_pool\n",
      "conv2_block1_preact_bn\n",
      "conv2_block1_preact_relu\n",
      "conv2_block1_1_conv\n",
      "conv2_block1_1_bn\n",
      "conv2_block1_1_relu\n",
      "conv2_block1_2_pad\n",
      "conv2_block1_2_conv\n",
      "conv2_block1_2_bn\n",
      "conv2_block1_2_relu\n",
      "conv2_block1_0_conv\n",
      "conv2_block1_3_conv\n",
      "conv2_block1_out\n",
      "conv2_block2_preact_bn\n",
      "conv2_block2_preact_relu\n",
      "conv2_block2_1_conv\n",
      "conv2_block2_1_bn\n",
      "conv2_block2_1_relu\n",
      "conv2_block2_2_pad\n",
      "conv2_block2_2_conv\n",
      "conv2_block2_2_bn\n",
      "conv2_block2_2_relu\n",
      "conv2_block2_3_conv\n",
      "conv2_block2_out\n",
      "conv2_block3_preact_bn\n",
      "conv2_block3_preact_relu\n",
      "conv2_block3_1_conv\n",
      "conv2_block3_1_bn\n",
      "conv2_block3_1_relu\n",
      "conv2_block3_2_pad\n",
      "conv2_block3_2_conv\n",
      "conv2_block3_2_bn\n",
      "conv2_block3_2_relu\n",
      "max_pooling2d\n",
      "conv2_block3_3_conv\n",
      "conv2_block3_out\n",
      "conv3_block1_preact_bn\n",
      "conv3_block1_preact_relu\n",
      "conv3_block1_1_conv\n",
      "conv3_block1_1_bn\n",
      "conv3_block1_1_relu\n",
      "conv3_block1_2_pad\n",
      "conv3_block1_2_conv\n",
      "conv3_block1_2_bn\n",
      "conv3_block1_2_relu\n",
      "conv3_block1_0_conv\n",
      "conv3_block1_3_conv\n",
      "conv3_block1_out\n",
      "conv3_block2_preact_bn\n",
      "conv3_block2_preact_relu\n",
      "conv3_block2_1_conv\n",
      "conv3_block2_1_bn\n",
      "conv3_block2_1_relu\n",
      "conv3_block2_2_pad\n",
      "conv3_block2_2_conv\n",
      "conv3_block2_2_bn\n",
      "conv3_block2_2_relu\n",
      "conv3_block2_3_conv\n",
      "conv3_block2_out\n",
      "conv3_block3_preact_bn\n",
      "conv3_block3_preact_relu\n",
      "conv3_block3_1_conv\n",
      "conv3_block3_1_bn\n",
      "conv3_block3_1_relu\n",
      "conv3_block3_2_pad\n",
      "conv3_block3_2_conv\n",
      "conv3_block3_2_bn\n",
      "conv3_block3_2_relu\n",
      "conv3_block3_3_conv\n",
      "conv3_block3_out\n",
      "conv3_block4_preact_bn\n",
      "conv3_block4_preact_relu\n",
      "conv3_block4_1_conv\n",
      "conv3_block4_1_bn\n",
      "conv3_block4_1_relu\n",
      "conv3_block4_2_pad\n",
      "conv3_block4_2_conv\n",
      "conv3_block4_2_bn\n",
      "conv3_block4_2_relu\n",
      "conv3_block4_3_conv\n",
      "conv3_block4_out\n",
      "conv3_block5_preact_bn\n",
      "conv3_block5_preact_relu\n",
      "conv3_block5_1_conv\n",
      "conv3_block5_1_bn\n",
      "conv3_block5_1_relu\n",
      "conv3_block5_2_pad\n",
      "conv3_block5_2_conv\n",
      "conv3_block5_2_bn\n",
      "conv3_block5_2_relu\n",
      "conv3_block5_3_conv\n",
      "conv3_block5_out\n",
      "conv3_block6_preact_bn\n",
      "conv3_block6_preact_relu\n",
      "conv3_block6_1_conv\n",
      "conv3_block6_1_bn\n",
      "conv3_block6_1_relu\n",
      "conv3_block6_2_pad\n",
      "conv3_block6_2_conv\n",
      "conv3_block6_2_bn\n",
      "conv3_block6_2_relu\n",
      "conv3_block6_3_conv\n",
      "conv3_block6_out\n",
      "conv3_block7_preact_bn\n",
      "conv3_block7_preact_relu\n",
      "conv3_block7_1_conv\n",
      "conv3_block7_1_bn\n",
      "conv3_block7_1_relu\n",
      "conv3_block7_2_pad\n",
      "conv3_block7_2_conv\n",
      "conv3_block7_2_bn\n",
      "conv3_block7_2_relu\n",
      "conv3_block7_3_conv\n",
      "conv3_block7_out\n",
      "conv3_block8_preact_bn\n",
      "conv3_block8_preact_relu\n",
      "conv3_block8_1_conv\n",
      "conv3_block8_1_bn\n",
      "conv3_block8_1_relu\n",
      "conv3_block8_2_pad\n",
      "conv3_block8_2_conv\n",
      "conv3_block8_2_bn\n",
      "conv3_block8_2_relu\n",
      "max_pooling2d_1\n",
      "conv3_block8_3_conv\n",
      "conv3_block8_out\n",
      "conv4_block1_preact_bn\n",
      "conv4_block1_preact_relu\n",
      "conv4_block1_1_conv\n",
      "conv4_block1_1_bn\n",
      "conv4_block1_1_relu\n",
      "conv4_block1_2_pad\n",
      "conv4_block1_2_conv\n",
      "conv4_block1_2_bn\n",
      "conv4_block1_2_relu\n",
      "conv4_block1_0_conv\n",
      "conv4_block1_3_conv\n",
      "conv4_block1_out\n",
      "conv4_block2_preact_bn\n",
      "conv4_block2_preact_relu\n",
      "conv4_block2_1_conv\n",
      "conv4_block2_1_bn\n",
      "conv4_block2_1_relu\n",
      "conv4_block2_2_pad\n",
      "conv4_block2_2_conv\n",
      "conv4_block2_2_bn\n",
      "conv4_block2_2_relu\n",
      "conv4_block2_3_conv\n",
      "conv4_block2_out\n",
      "conv4_block3_preact_bn\n",
      "conv4_block3_preact_relu\n",
      "conv4_block3_1_conv\n",
      "conv4_block3_1_bn\n",
      "conv4_block3_1_relu\n",
      "conv4_block3_2_pad\n",
      "conv4_block3_2_conv\n",
      "conv4_block3_2_bn\n",
      "conv4_block3_2_relu\n",
      "conv4_block3_3_conv\n",
      "conv4_block3_out\n",
      "conv4_block4_preact_bn\n",
      "conv4_block4_preact_relu\n",
      "conv4_block4_1_conv\n",
      "conv4_block4_1_bn\n",
      "conv4_block4_1_relu\n",
      "conv4_block4_2_pad\n",
      "conv4_block4_2_conv\n",
      "conv4_block4_2_bn\n",
      "conv4_block4_2_relu\n",
      "conv4_block4_3_conv\n",
      "conv4_block4_out\n",
      "conv4_block5_preact_bn\n",
      "conv4_block5_preact_relu\n",
      "conv4_block5_1_conv\n",
      "conv4_block5_1_bn\n",
      "conv4_block5_1_relu\n",
      "conv4_block5_2_pad\n",
      "conv4_block5_2_conv\n",
      "conv4_block5_2_bn\n",
      "conv4_block5_2_relu\n",
      "conv4_block5_3_conv\n",
      "conv4_block5_out\n",
      "conv4_block6_preact_bn\n",
      "conv4_block6_preact_relu\n",
      "conv4_block6_1_conv\n",
      "conv4_block6_1_bn\n",
      "conv4_block6_1_relu\n",
      "conv4_block6_2_pad\n",
      "conv4_block6_2_conv\n",
      "conv4_block6_2_bn\n",
      "conv4_block6_2_relu\n",
      "conv4_block6_3_conv\n",
      "conv4_block6_out\n",
      "conv4_block7_preact_bn\n",
      "conv4_block7_preact_relu\n",
      "conv4_block7_1_conv\n",
      "conv4_block7_1_bn\n",
      "conv4_block7_1_relu\n",
      "conv4_block7_2_pad\n",
      "conv4_block7_2_conv\n",
      "conv4_block7_2_bn\n",
      "conv4_block7_2_relu\n",
      "conv4_block7_3_conv\n",
      "conv4_block7_out\n",
      "conv4_block8_preact_bn\n",
      "conv4_block8_preact_relu\n",
      "conv4_block8_1_conv\n",
      "conv4_block8_1_bn\n",
      "conv4_block8_1_relu\n",
      "conv4_block8_2_pad\n",
      "conv4_block8_2_conv\n",
      "conv4_block8_2_bn\n",
      "conv4_block8_2_relu\n",
      "conv4_block8_3_conv\n",
      "conv4_block8_out\n",
      "conv4_block9_preact_bn\n",
      "conv4_block9_preact_relu\n",
      "conv4_block9_1_conv\n",
      "conv4_block9_1_bn\n",
      "conv4_block9_1_relu\n",
      "conv4_block9_2_pad\n",
      "conv4_block9_2_conv\n",
      "conv4_block9_2_bn\n",
      "conv4_block9_2_relu\n",
      "conv4_block9_3_conv\n",
      "conv4_block9_out\n",
      "conv4_block10_preact_bn\n",
      "conv4_block10_preact_relu\n",
      "conv4_block10_1_conv\n",
      "conv4_block10_1_bn\n",
      "conv4_block10_1_relu\n",
      "conv4_block10_2_pad\n",
      "conv4_block10_2_conv\n",
      "conv4_block10_2_bn\n",
      "conv4_block10_2_relu\n",
      "conv4_block10_3_conv\n",
      "conv4_block10_out\n",
      "conv4_block11_preact_bn\n",
      "conv4_block11_preact_relu\n",
      "conv4_block11_1_conv\n",
      "conv4_block11_1_bn\n",
      "conv4_block11_1_relu\n",
      "conv4_block11_2_pad\n",
      "conv4_block11_2_conv\n",
      "conv4_block11_2_bn\n",
      "conv4_block11_2_relu\n",
      "conv4_block11_3_conv\n",
      "conv4_block11_out\n",
      "conv4_block12_preact_bn\n",
      "conv4_block12_preact_relu\n",
      "conv4_block12_1_conv\n",
      "conv4_block12_1_bn\n",
      "conv4_block12_1_relu\n",
      "conv4_block12_2_pad\n",
      "conv4_block12_2_conv\n",
      "conv4_block12_2_bn\n",
      "conv4_block12_2_relu\n",
      "conv4_block12_3_conv\n",
      "conv4_block12_out\n",
      "conv4_block13_preact_bn\n",
      "conv4_block13_preact_relu\n",
      "conv4_block13_1_conv\n",
      "conv4_block13_1_bn\n",
      "conv4_block13_1_relu\n",
      "conv4_block13_2_pad\n",
      "conv4_block13_2_conv\n",
      "conv4_block13_2_bn\n",
      "conv4_block13_2_relu\n",
      "conv4_block13_3_conv\n",
      "conv4_block13_out\n",
      "conv4_block14_preact_bn\n",
      "conv4_block14_preact_relu\n",
      "conv4_block14_1_conv\n",
      "conv4_block14_1_bn\n",
      "conv4_block14_1_relu\n",
      "conv4_block14_2_pad\n",
      "conv4_block14_2_conv\n",
      "conv4_block14_2_bn\n",
      "conv4_block14_2_relu\n",
      "conv4_block14_3_conv\n",
      "conv4_block14_out\n",
      "conv4_block15_preact_bn\n",
      "conv4_block15_preact_relu\n",
      "conv4_block15_1_conv\n",
      "conv4_block15_1_bn\n",
      "conv4_block15_1_relu\n",
      "conv4_block15_2_pad\n",
      "conv4_block15_2_conv\n",
      "conv4_block15_2_bn\n",
      "conv4_block15_2_relu\n",
      "conv4_block15_3_conv\n",
      "conv4_block15_out\n",
      "conv4_block16_preact_bn\n",
      "conv4_block16_preact_relu\n",
      "conv4_block16_1_conv\n",
      "conv4_block16_1_bn\n",
      "conv4_block16_1_relu\n",
      "conv4_block16_2_pad\n",
      "conv4_block16_2_conv\n",
      "conv4_block16_2_bn\n",
      "conv4_block16_2_relu\n",
      "conv4_block16_3_conv\n",
      "conv4_block16_out\n",
      "conv4_block17_preact_bn\n",
      "conv4_block17_preact_relu\n",
      "conv4_block17_1_conv\n",
      "conv4_block17_1_bn\n",
      "conv4_block17_1_relu\n",
      "conv4_block17_2_pad\n",
      "conv4_block17_2_conv\n",
      "conv4_block17_2_bn\n",
      "conv4_block17_2_relu\n",
      "conv4_block17_3_conv\n",
      "conv4_block17_out\n",
      "conv4_block18_preact_bn\n",
      "conv4_block18_preact_relu\n",
      "conv4_block18_1_conv\n",
      "conv4_block18_1_bn\n",
      "conv4_block18_1_relu\n",
      "conv4_block18_2_pad\n",
      "conv4_block18_2_conv\n",
      "conv4_block18_2_bn\n",
      "conv4_block18_2_relu\n",
      "conv4_block18_3_conv\n",
      "conv4_block18_out\n",
      "conv4_block19_preact_bn\n",
      "conv4_block19_preact_relu\n",
      "conv4_block19_1_conv\n",
      "conv4_block19_1_bn\n",
      "conv4_block19_1_relu\n",
      "conv4_block19_2_pad\n",
      "conv4_block19_2_conv\n",
      "conv4_block19_2_bn\n",
      "conv4_block19_2_relu\n",
      "conv4_block19_3_conv\n",
      "conv4_block19_out\n",
      "conv4_block20_preact_bn\n",
      "conv4_block20_preact_relu\n",
      "conv4_block20_1_conv\n",
      "conv4_block20_1_bn\n",
      "conv4_block20_1_relu\n",
      "conv4_block20_2_pad\n",
      "conv4_block20_2_conv\n",
      "conv4_block20_2_bn\n",
      "conv4_block20_2_relu\n",
      "conv4_block20_3_conv\n",
      "conv4_block20_out\n",
      "conv4_block21_preact_bn\n",
      "conv4_block21_preact_relu\n",
      "conv4_block21_1_conv\n",
      "conv4_block21_1_bn\n",
      "conv4_block21_1_relu\n",
      "conv4_block21_2_pad\n",
      "conv4_block21_2_conv\n",
      "conv4_block21_2_bn\n",
      "conv4_block21_2_relu\n",
      "conv4_block21_3_conv\n",
      "conv4_block21_out\n",
      "conv4_block22_preact_bn\n",
      "conv4_block22_preact_relu\n",
      "conv4_block22_1_conv\n",
      "conv4_block22_1_bn\n",
      "conv4_block22_1_relu\n",
      "conv4_block22_2_pad\n",
      "conv4_block22_2_conv\n",
      "conv4_block22_2_bn\n",
      "conv4_block22_2_relu\n",
      "conv4_block22_3_conv\n",
      "conv4_block22_out\n",
      "conv4_block23_preact_bn\n",
      "conv4_block23_preact_relu\n",
      "conv4_block23_1_conv\n",
      "conv4_block23_1_bn\n",
      "conv4_block23_1_relu\n",
      "conv4_block23_2_pad\n",
      "conv4_block23_2_conv\n",
      "conv4_block23_2_bn\n",
      "conv4_block23_2_relu\n",
      "conv4_block23_3_conv\n",
      "conv4_block23_out\n",
      "conv4_block24_preact_bn\n",
      "conv4_block24_preact_relu\n",
      "conv4_block24_1_conv\n",
      "conv4_block24_1_bn\n",
      "conv4_block24_1_relu\n",
      "conv4_block24_2_pad\n",
      "conv4_block24_2_conv\n",
      "conv4_block24_2_bn\n",
      "conv4_block24_2_relu\n",
      "conv4_block24_3_conv\n",
      "conv4_block24_out\n",
      "conv4_block25_preact_bn\n",
      "conv4_block25_preact_relu\n",
      "conv4_block25_1_conv\n",
      "conv4_block25_1_bn\n",
      "conv4_block25_1_relu\n",
      "conv4_block25_2_pad\n",
      "conv4_block25_2_conv\n",
      "conv4_block25_2_bn\n",
      "conv4_block25_2_relu\n",
      "conv4_block25_3_conv\n",
      "conv4_block25_out\n",
      "conv4_block26_preact_bn\n",
      "conv4_block26_preact_relu\n",
      "conv4_block26_1_conv\n",
      "conv4_block26_1_bn\n",
      "conv4_block26_1_relu\n",
      "conv4_block26_2_pad\n",
      "conv4_block26_2_conv\n",
      "conv4_block26_2_bn\n",
      "conv4_block26_2_relu\n",
      "conv4_block26_3_conv\n",
      "conv4_block26_out\n",
      "conv4_block27_preact_bn\n",
      "conv4_block27_preact_relu\n",
      "conv4_block27_1_conv\n",
      "conv4_block27_1_bn\n",
      "conv4_block27_1_relu\n",
      "conv4_block27_2_pad\n",
      "conv4_block27_2_conv\n",
      "conv4_block27_2_bn\n",
      "conv4_block27_2_relu\n",
      "conv4_block27_3_conv\n",
      "conv4_block27_out\n",
      "conv4_block28_preact_bn\n",
      "conv4_block28_preact_relu\n",
      "conv4_block28_1_conv\n",
      "conv4_block28_1_bn\n",
      "conv4_block28_1_relu\n",
      "conv4_block28_2_pad\n",
      "conv4_block28_2_conv\n",
      "conv4_block28_2_bn\n",
      "conv4_block28_2_relu\n",
      "conv4_block28_3_conv\n",
      "conv4_block28_out\n",
      "conv4_block29_preact_bn\n",
      "conv4_block29_preact_relu\n",
      "conv4_block29_1_conv\n",
      "conv4_block29_1_bn\n",
      "conv4_block29_1_relu\n",
      "conv4_block29_2_pad\n",
      "conv4_block29_2_conv\n",
      "conv4_block29_2_bn\n",
      "conv4_block29_2_relu\n",
      "conv4_block29_3_conv\n",
      "conv4_block29_out\n",
      "conv4_block30_preact_bn\n",
      "conv4_block30_preact_relu\n",
      "conv4_block30_1_conv\n",
      "conv4_block30_1_bn\n",
      "conv4_block30_1_relu\n",
      "conv4_block30_2_pad\n",
      "conv4_block30_2_conv\n",
      "conv4_block30_2_bn\n",
      "conv4_block30_2_relu\n",
      "conv4_block30_3_conv\n",
      "conv4_block30_out\n",
      "conv4_block31_preact_bn\n",
      "conv4_block31_preact_relu\n",
      "conv4_block31_1_conv\n",
      "conv4_block31_1_bn\n",
      "conv4_block31_1_relu\n",
      "conv4_block31_2_pad\n",
      "conv4_block31_2_conv\n",
      "conv4_block31_2_bn\n",
      "conv4_block31_2_relu\n",
      "conv4_block31_3_conv\n",
      "conv4_block31_out\n",
      "conv4_block32_preact_bn\n",
      "conv4_block32_preact_relu\n",
      "conv4_block32_1_conv\n",
      "conv4_block32_1_bn\n",
      "conv4_block32_1_relu\n",
      "conv4_block32_2_pad\n",
      "conv4_block32_2_conv\n",
      "conv4_block32_2_bn\n",
      "conv4_block32_2_relu\n",
      "conv4_block32_3_conv\n",
      "conv4_block32_out\n",
      "conv4_block33_preact_bn\n",
      "conv4_block33_preact_relu\n",
      "conv4_block33_1_conv\n",
      "conv4_block33_1_bn\n",
      "conv4_block33_1_relu\n",
      "conv4_block33_2_pad\n",
      "conv4_block33_2_conv\n",
      "conv4_block33_2_bn\n",
      "conv4_block33_2_relu\n",
      "conv4_block33_3_conv\n",
      "conv4_block33_out\n",
      "conv4_block34_preact_bn\n",
      "conv4_block34_preact_relu\n",
      "conv4_block34_1_conv\n",
      "conv4_block34_1_bn\n",
      "conv4_block34_1_relu\n",
      "conv4_block34_2_pad\n",
      "conv4_block34_2_conv\n",
      "conv4_block34_2_bn\n",
      "conv4_block34_2_relu\n",
      "conv4_block34_3_conv\n",
      "conv4_block34_out\n",
      "conv4_block35_preact_bn\n",
      "conv4_block35_preact_relu\n",
      "conv4_block35_1_conv\n",
      "conv4_block35_1_bn\n",
      "conv4_block35_1_relu\n",
      "conv4_block35_2_pad\n",
      "conv4_block35_2_conv\n",
      "conv4_block35_2_bn\n",
      "conv4_block35_2_relu\n",
      "conv4_block35_3_conv\n",
      "conv4_block35_out\n",
      "conv4_block36_preact_bn\n",
      "conv4_block36_preact_relu\n",
      "conv4_block36_1_conv\n",
      "conv4_block36_1_bn\n",
      "conv4_block36_1_relu\n",
      "conv4_block36_2_pad\n",
      "conv4_block36_2_conv\n",
      "conv4_block36_2_bn\n",
      "conv4_block36_2_relu\n",
      "max_pooling2d_2\n",
      "conv4_block36_3_conv\n",
      "conv4_block36_out\n",
      "conv5_block1_preact_bn\n",
      "conv5_block1_preact_relu\n",
      "conv5_block1_1_conv\n",
      "conv5_block1_1_bn\n",
      "conv5_block1_1_relu\n",
      "conv5_block1_2_pad\n",
      "conv5_block1_2_conv\n",
      "conv5_block1_2_bn\n",
      "conv5_block1_2_relu\n",
      "conv5_block1_0_conv\n",
      "conv5_block1_3_conv\n",
      "conv5_block1_out\n",
      "conv5_block2_preact_bn\n",
      "conv5_block2_preact_relu\n",
      "conv5_block2_1_conv\n",
      "conv5_block2_1_bn\n",
      "conv5_block2_1_relu\n",
      "conv5_block2_2_pad\n",
      "conv5_block2_2_conv\n",
      "conv5_block2_2_bn\n",
      "conv5_block2_2_relu\n",
      "conv5_block2_3_conv\n",
      "conv5_block2_out\n",
      "conv5_block3_preact_bn\n",
      "conv5_block3_preact_relu\n",
      "conv5_block3_1_conv\n",
      "conv5_block3_1_bn\n",
      "conv5_block3_1_relu\n",
      "conv5_block3_2_pad\n",
      "conv5_block3_2_conv\n",
      "conv5_block3_2_bn\n",
      "conv5_block3_2_relu\n",
      "conv5_block3_3_conv\n",
      "conv5_block3_out\n",
      "post_bn\n",
      "post_relu\n",
      "avg_pool\n",
      "predictions\n"
     ]
    }
   ],
   "source": [
    "for layer in base_model.layers:\n",
    "  print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1712712458236,
     "user": {
      "displayName": "zai wang",
      "userId": "09044436193906041350"
     },
     "user_tz": -480
    },
    "id": "DeCb9uxlizAw"
   },
   "outputs": [],
   "source": [
    "trainable = False\n",
    "for layer in base_model.layers:\n",
    "    if layer.name == 'conv5_block1_preact_bn':\n",
    "        trainable = True\n",
    "    layer.trainable = trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 1914,
     "status": "ok",
     "timestamp": 1712712460139,
     "user": {
      "displayName": "zai wang",
      "userId": "09044436193906041350"
     },
     "user_tz": -480
    },
    "id": "W1ZBpQPkizAw"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1024, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(100, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1712712460139,
     "user": {
      "displayName": "zai wang",
      "userId": "09044436193906041350"
     },
     "user_tz": -480
    },
    "id": "W7CUP_R9mIFB"
   },
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1712712460139,
     "user": {
      "displayName": "zai wang",
      "userId": "09044436193906041350"
     },
     "user_tz": -480
    },
    "id": "J6LXQ19EizAw",
    "outputId": "68db3295-8dbc-478b-a7b1-18bd44810283"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet152v2 (Functional)    (None, 1000)              60380648  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1000)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              1025024   \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 1024)              4096      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               102500    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61512268 (234.65 MB)\n",
      "Trainable params: 18149452 (69.23 MB)\n",
      "Non-trainable params: 43362816 (165.42 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1712712460139,
     "user": {
      "displayName": "zai wang",
      "userId": "09044436193906041350"
     },
     "user_tz": -480
    },
    "id": "elnXjCVoHhqu"
   },
   "outputs": [],
   "source": [
    "# Definition optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "# Defined loss function\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "# Define evaluation indicators\n",
    "metrics = [\n",
    "    tf.keras.metrics.CategoricalAccuracy(),\n",
    "    tf.keras.metrics.Precision(),\n",
    "    tf.keras.metrics.Recall(),\n",
    "]\n",
    "\n",
    "# Compilation model\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1712712460139,
     "user": {
      "displayName": "zai wang",
      "userId": "09044436193906041350"
     },
     "user_tz": -480
    },
    "id": "fX5m0ERi_H5k"
   },
   "outputs": [],
   "source": [
    "log_dir = \"../Running result/resnet152v2/resnet152v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1712712460139,
     "user": {
      "displayName": "zai wang",
      "userId": "09044436193906041350"
     },
     "user_tz": -480
    },
    "id": "5Xbprmsdav-G"
   },
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1712712460139,
     "user": {
      "displayName": "zai wang",
      "userId": "09044436193906041350"
     },
     "user_tz": -480
    },
    "id": "XGADws7aCwEK"
   },
   "outputs": [],
   "source": [
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=2, min_lr=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2306894,
     "status": "ok",
     "timestamp": 1712714767028,
     "user": {
      "displayName": "zai wang",
      "userId": "09044436193906041350"
     },
     "user_tz": -480
    },
    "id": "_r9__PlFizAx",
    "outputId": "5bfe4ecb-c752-403f-b4e9-cef85268553d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 10:52:56.569796: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-10-26 10:52:56.794111: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-10-26 10:52:59.325509: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f0fd58b7830 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-10-26 10:52:59.325558: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2024-10-26 10:52:59.325567: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2024-10-26 10:52:59.339210: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1729911179.523167    1622 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 55s 198ms/step - loss: 3.7854 - categorical_accuracy: 0.1940 - precision: 0.7558 - recall: 0.0346 - val_loss: 4.3789 - val_categorical_accuracy: 0.3111 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "176/176 [==============================] - 31s 171ms/step - loss: 2.4306 - categorical_accuracy: 0.4132 - precision: 0.7646 - recall: 0.2154 - val_loss: 3.7569 - val_categorical_accuracy: 0.4496 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "176/176 [==============================] - 29s 165ms/step - loss: 1.8000 - categorical_accuracy: 0.5338 - precision: 0.8037 - recall: 0.3578 - val_loss: 2.5283 - val_categorical_accuracy: 0.5312 - val_precision: 1.0000 - val_recall: 3.5511e-04 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "176/176 [==============================] - 30s 168ms/step - loss: 1.4189 - categorical_accuracy: 0.6247 - precision: 0.8257 - recall: 0.4760 - val_loss: 1.5025 - val_categorical_accuracy: 0.6346 - val_precision: 0.8774 - val_recall: 0.4268 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "176/176 [==============================] - 30s 167ms/step - loss: 1.1676 - categorical_accuracy: 0.6810 - precision: 0.8493 - recall: 0.5530 - val_loss: 1.2433 - val_categorical_accuracy: 0.6690 - val_precision: 0.8262 - val_recall: 0.5639 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "176/176 [==============================] - 29s 164ms/step - loss: 0.9758 - categorical_accuracy: 0.7310 - precision: 0.8636 - recall: 0.6320 - val_loss: 1.1097 - val_categorical_accuracy: 0.7031 - val_precision: 0.8440 - val_recall: 0.6012 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "176/176 [==============================] - 30s 166ms/step - loss: 0.8033 - categorical_accuracy: 0.7743 - precision: 0.8874 - recall: 0.6847 - val_loss: 0.9773 - val_categorical_accuracy: 0.7418 - val_precision: 0.8520 - val_recall: 0.6665 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "176/176 [==============================] - 30s 169ms/step - loss: 0.6887 - categorical_accuracy: 0.8062 - precision: 0.8973 - recall: 0.7263 - val_loss: 0.9071 - val_categorical_accuracy: 0.7628 - val_precision: 0.8626 - val_recall: 0.6797 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "176/176 [==============================] - 30s 166ms/step - loss: 0.6070 - categorical_accuracy: 0.8266 - precision: 0.9044 - recall: 0.7631 - val_loss: 0.8261 - val_categorical_accuracy: 0.7777 - val_precision: 0.8669 - val_recall: 0.7191 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "176/176 [==============================] - 30s 166ms/step - loss: 0.5242 - categorical_accuracy: 0.8543 - precision: 0.9179 - recall: 0.7992 - val_loss: 0.8163 - val_categorical_accuracy: 0.7827 - val_precision: 0.8526 - val_recall: 0.7354 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "176/176 [==============================] - 30s 166ms/step - loss: 0.4502 - categorical_accuracy: 0.8712 - precision: 0.9216 - recall: 0.8236 - val_loss: 0.7598 - val_categorical_accuracy: 0.7962 - val_precision: 0.8703 - val_recall: 0.7557 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "176/176 [==============================] - 31s 173ms/step - loss: 0.4298 - categorical_accuracy: 0.8757 - precision: 0.9232 - recall: 0.8341 - val_loss: 0.7669 - val_categorical_accuracy: 0.7983 - val_precision: 0.8654 - val_recall: 0.7578 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "176/176 [==============================] - 31s 172ms/step - loss: 0.3894 - categorical_accuracy: 0.8889 - precision: 0.9303 - recall: 0.8526 - val_loss: 0.7804 - val_categorical_accuracy: 0.8022 - val_precision: 0.8689 - val_recall: 0.7599 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "176/176 [==============================] - 31s 172ms/step - loss: 0.3510 - categorical_accuracy: 0.8991 - precision: 0.9378 - recall: 0.8675 - val_loss: 0.7175 - val_categorical_accuracy: 0.8150 - val_precision: 0.8812 - val_recall: 0.7827 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "176/176 [==============================] - 30s 167ms/step - loss: 0.3157 - categorical_accuracy: 0.9089 - precision: 0.9428 - recall: 0.8828 - val_loss: 0.7166 - val_categorical_accuracy: 0.8217 - val_precision: 0.8704 - val_recall: 0.7919 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "176/176 [==============================] - 31s 174ms/step - loss: 0.3028 - categorical_accuracy: 0.9118 - precision: 0.9426 - recall: 0.8853 - val_loss: 0.6742 - val_categorical_accuracy: 0.8263 - val_precision: 0.8849 - val_recall: 0.7972 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "176/176 [==============================] - 33s 187ms/step - loss: 0.2653 - categorical_accuracy: 0.9260 - precision: 0.9487 - recall: 0.9027 - val_loss: 0.7096 - val_categorical_accuracy: 0.8242 - val_precision: 0.8688 - val_recall: 0.7926 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "176/176 [==============================] - 33s 183ms/step - loss: 0.2609 - categorical_accuracy: 0.9260 - precision: 0.9489 - recall: 0.9033 - val_loss: 0.6940 - val_categorical_accuracy: 0.8374 - val_precision: 0.8773 - val_recall: 0.8100 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "176/176 [==============================] - 30s 170ms/step - loss: 0.2213 - categorical_accuracy: 0.9362 - precision: 0.9565 - recall: 0.9181 - val_loss: 0.6367 - val_categorical_accuracy: 0.8505 - val_precision: 0.8888 - val_recall: 0.8232 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "176/176 [==============================] - 30s 169ms/step - loss: 0.2166 - categorical_accuracy: 0.9386 - precision: 0.9561 - recall: 0.9216 - val_loss: 0.7186 - val_categorical_accuracy: 0.8327 - val_precision: 0.8740 - val_recall: 0.8079 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "176/176 [==============================] - 31s 172ms/step - loss: 0.2042 - categorical_accuracy: 0.9417 - precision: 0.9579 - recall: 0.9235 - val_loss: 0.6578 - val_categorical_accuracy: 0.8448 - val_precision: 0.8874 - val_recall: 0.8196 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "176/176 [==============================] - 30s 168ms/step - loss: 0.1512 - categorical_accuracy: 0.9562 - precision: 0.9690 - recall: 0.9436 - val_loss: 0.5809 - val_categorical_accuracy: 0.8640 - val_precision: 0.8975 - val_recall: 0.8398 - lr: 5.0000e-05\n",
      "Epoch 23/50\n",
      "176/176 [==============================] - 30s 167ms/step - loss: 0.1184 - categorical_accuracy: 0.9641 - precision: 0.9750 - recall: 0.9539 - val_loss: 0.5706 - val_categorical_accuracy: 0.8693 - val_precision: 0.8961 - val_recall: 0.8487 - lr: 5.0000e-05\n",
      "Epoch 24/50\n",
      "176/176 [==============================] - 30s 168ms/step - loss: 0.1032 - categorical_accuracy: 0.9718 - precision: 0.9786 - recall: 0.9642 - val_loss: 0.5928 - val_categorical_accuracy: 0.8647 - val_precision: 0.8903 - val_recall: 0.8473 - lr: 5.0000e-05\n",
      "Epoch 25/50\n",
      "176/176 [==============================] - 31s 175ms/step - loss: 0.1041 - categorical_accuracy: 0.9704 - precision: 0.9785 - recall: 0.9620 - val_loss: 0.5731 - val_categorical_accuracy: 0.8729 - val_precision: 0.9005 - val_recall: 0.8580 - lr: 5.0000e-05\n",
      "Epoch 26/50\n",
      "176/176 [==============================] - 30s 169ms/step - loss: 0.0949 - categorical_accuracy: 0.9719 - precision: 0.9791 - recall: 0.9650 - val_loss: 0.5650 - val_categorical_accuracy: 0.8683 - val_precision: 0.8945 - val_recall: 0.8548 - lr: 5.0000e-05\n",
      "Epoch 27/50\n",
      "176/176 [==============================] - 30s 171ms/step - loss: 0.0886 - categorical_accuracy: 0.9735 - precision: 0.9798 - recall: 0.9669 - val_loss: 0.5882 - val_categorical_accuracy: 0.8693 - val_precision: 0.8965 - val_recall: 0.8551 - lr: 5.0000e-05\n",
      "Epoch 28/50\n",
      "176/176 [==============================] - 30s 169ms/step - loss: 0.0817 - categorical_accuracy: 0.9758 - precision: 0.9834 - recall: 0.9686 - val_loss: 0.5552 - val_categorical_accuracy: 0.8739 - val_precision: 0.9001 - val_recall: 0.8612 - lr: 2.5000e-05\n",
      "Epoch 29/50\n",
      "176/176 [==============================] - 31s 172ms/step - loss: 0.0661 - categorical_accuracy: 0.9818 - precision: 0.9867 - recall: 0.9749 - val_loss: 0.5487 - val_categorical_accuracy: 0.8739 - val_precision: 0.9013 - val_recall: 0.8629 - lr: 2.5000e-05\n",
      "Epoch 30/50\n",
      "176/176 [==============================] - 31s 171ms/step - loss: 0.0621 - categorical_accuracy: 0.9794 - precision: 0.9838 - recall: 0.9746 - val_loss: 0.5463 - val_categorical_accuracy: 0.8793 - val_precision: 0.9048 - val_recall: 0.8640 - lr: 2.5000e-05\n",
      "Epoch 31/50\n",
      "176/176 [==============================] - 32s 178ms/step - loss: 0.0588 - categorical_accuracy: 0.9833 - precision: 0.9876 - recall: 0.9782 - val_loss: 0.5408 - val_categorical_accuracy: 0.8789 - val_precision: 0.9013 - val_recall: 0.8622 - lr: 2.5000e-05\n",
      "Epoch 32/50\n",
      "176/176 [==============================] - 31s 172ms/step - loss: 0.0545 - categorical_accuracy: 0.9832 - precision: 0.9862 - recall: 0.9786 - val_loss: 0.5580 - val_categorical_accuracy: 0.8810 - val_precision: 0.9014 - val_recall: 0.8636 - lr: 2.5000e-05\n",
      "Epoch 33/50\n",
      "176/176 [==============================] - 31s 172ms/step - loss: 0.0539 - categorical_accuracy: 0.9838 - precision: 0.9869 - recall: 0.9797 - val_loss: 0.5560 - val_categorical_accuracy: 0.8796 - val_precision: 0.9039 - val_recall: 0.8647 - lr: 2.5000e-05\n",
      "Epoch 34/50\n",
      "176/176 [==============================] - 31s 172ms/step - loss: 0.0547 - categorical_accuracy: 0.9847 - precision: 0.9883 - recall: 0.9805 - val_loss: 0.5419 - val_categorical_accuracy: 0.8750 - val_precision: 0.9015 - val_recall: 0.8643 - lr: 2.5000e-05\n",
      "Epoch 35/50\n",
      "176/176 [==============================] - 30s 166ms/step - loss: 0.0442 - categorical_accuracy: 0.9869 - precision: 0.9901 - recall: 0.9842 - val_loss: 0.5376 - val_categorical_accuracy: 0.8782 - val_precision: 0.8999 - val_recall: 0.8651 - lr: 1.2500e-05\n",
      "Epoch 36/50\n",
      "176/176 [==============================] - 30s 168ms/step - loss: 0.0471 - categorical_accuracy: 0.9854 - precision: 0.9881 - recall: 0.9821 - val_loss: 0.5302 - val_categorical_accuracy: 0.8825 - val_precision: 0.9035 - val_recall: 0.8714 - lr: 1.2500e-05\n",
      "Epoch 37/50\n",
      "176/176 [==============================] - 31s 172ms/step - loss: 0.0445 - categorical_accuracy: 0.9862 - precision: 0.9887 - recall: 0.9825 - val_loss: 0.5271 - val_categorical_accuracy: 0.8842 - val_precision: 0.9043 - val_recall: 0.8722 - lr: 1.2500e-05\n",
      "Epoch 38/50\n",
      "176/176 [==============================] - 32s 179ms/step - loss: 0.0370 - categorical_accuracy: 0.9878 - precision: 0.9911 - recall: 0.9853 - val_loss: 0.5465 - val_categorical_accuracy: 0.8849 - val_precision: 0.9049 - val_recall: 0.8714 - lr: 1.2500e-05\n",
      "Epoch 41/50\n",
      "176/176 [==============================] - 31s 174ms/step - loss: 0.0390 - categorical_accuracy: 0.9885 - precision: 0.9906 - recall: 0.9865 - val_loss: 0.5487 - val_categorical_accuracy: 0.8867 - val_precision: 0.9046 - val_recall: 0.8725 - lr: 6.2500e-06\n",
      "Epoch 42/50\n",
      "176/176 [==============================] - 31s 172ms/step - loss: 0.0364 - categorical_accuracy: 0.9876 - precision: 0.9905 - recall: 0.9861 - val_loss: 0.5451 - val_categorical_accuracy: 0.8860 - val_precision: 0.9080 - val_recall: 0.8725 - lr: 6.2500e-06\n",
      "Epoch 43/50\n",
      "176/176 [==============================] - 30s 168ms/step - loss: 0.0367 - categorical_accuracy: 0.9890 - precision: 0.9913 - recall: 0.9867 - val_loss: 0.5457 - val_categorical_accuracy: 0.8878 - val_precision: 0.9083 - val_recall: 0.8725 - lr: 6.2500e-06\n",
      "Epoch 44/50\n",
      "176/176 [==============================] - 30s 170ms/step - loss: 0.0340 - categorical_accuracy: 0.9898 - precision: 0.9921 - recall: 0.9873 - val_loss: 0.5359 - val_categorical_accuracy: 0.8892 - val_precision: 0.9069 - val_recall: 0.8750 - lr: 6.2500e-06\n",
      "Epoch 45/50\n",
      "176/176 [==============================] - 32s 179ms/step - loss: 0.0329 - categorical_accuracy: 0.9891 - precision: 0.9914 - recall: 0.9871 - val_loss: 0.5380 - val_categorical_accuracy: 0.8874 - val_precision: 0.9076 - val_recall: 0.8750 - lr: 6.2500e-06\n",
      "Epoch 46/50\n",
      "176/176 [==============================] - 32s 179ms/step - loss: 0.0336 - categorical_accuracy: 0.9896 - precision: 0.9917 - recall: 0.9873 - val_loss: 0.5420 - val_categorical_accuracy: 0.8878 - val_precision: 0.9083 - val_recall: 0.8757 - lr: 6.2500e-06\n",
      "Epoch 47/50\n",
      "176/176 [==============================] - 30s 166ms/step - loss: 0.0322 - categorical_accuracy: 0.9905 - precision: 0.9924 - recall: 0.9883 - val_loss: 0.5420 - val_categorical_accuracy: 0.8896 - val_precision: 0.9095 - val_recall: 0.8746 - lr: 3.1250e-06\n",
      "Epoch 48/50\n",
      "176/176 [==============================] - 32s 179ms/step - loss: 0.0313 - categorical_accuracy: 0.9895 - precision: 0.9909 - recall: 0.9876 - val_loss: 0.5421 - val_categorical_accuracy: 0.8885 - val_precision: 0.9096 - val_recall: 0.8750 - lr: 3.1250e-06\n",
      "Epoch 49/50\n",
      "176/176 [==============================] - 31s 172ms/step - loss: 0.0322 - categorical_accuracy: 0.9894 - precision: 0.9914 - recall: 0.9872 - val_loss: 0.5364 - val_categorical_accuracy: 0.8888 - val_precision: 0.9104 - val_recall: 0.8768 - lr: 3.1250e-06\n",
      "Epoch 50/50\n",
      "176/176 [==============================] - 31s 173ms/step - loss: 0.0304 - categorical_accuracy: 0.9912 - precision: 0.9929 - recall: 0.9894 - val_loss: 0.5373 - val_categorical_accuracy: 0.8903 - val_precision: 0.9100 - val_recall: 0.8764 - lr: 1.5625e-06\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds,epochs=EPOCHS,validation_data=vaild_ds,callbacks=[lr_scheduler,tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training history saved to: ../Running result/resent152v2/resent152v2.xlsx\n",
      "Model saved to: ../Running result/resent152v2/resnet152v2.h5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # Import the Pandas library\n",
    "import os\n",
    "\n",
    "# Assume the model has been trained and 'history' contains the training history\n",
    "\n",
    "# Define save path\n",
    "model_dir = \"../Running result/resent152v2\"\n",
    "excel_file_path = os.path.join(model_dir, \"resent152v2.xlsx\")  # Path to save the Excel file\n",
    "model_file_path = os.path.join(model_dir, \"resnet152v2.h5\")  # Path to save the model\n",
    "\n",
    "# Check if the save directory exists, create it if not\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "# Save the training history to an Excel file\n",
    "history_df = pd.DataFrame(history.history)  \n",
    "history_df.to_excel(excel_file_path, index=False)\n",
    "print(f\"Training history saved to: {excel_file_path}\")\n",
    "\n",
    "# Save the model to the specified path\n",
    "model.save(model_file_path)\n",
    "print(f\"Model saved to: {model_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1712714823670,
     "user": {
      "displayName": "zai wang",
      "userId": "09044436193906041350"
     },
     "user_tz": -480
    },
    "id": "DMwCaSfvav-G",
    "outputId": "2653ea31-397e-4e00-9b90-baf7dadf837b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from PIL import Image\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Input\n",
    "\n",
    "# Force GPU operations to be synchronized to ensure accurate timing\n",
    "tf.config.experimental.set_synchronous_execution(True)\n",
    "\n",
    "# Set TensorFlow log level to output only errors\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "# Create Model (VGG16)\n",
    "def create_model():\n",
    "    inputs = Input(shape=(224, 224, 3))\n",
    "    # Use VGG16 as the base model without the top layers\n",
    "    base_model = tf.keras.applications.VGG16(input_shape=(224, 224, 3), include_top=False, weights='imagenet', input_tensor=inputs)\n",
    "    \n",
    "    x = base_model(inputs)\n",
    "    x = GlobalAveragePooling2D()(x)  # Global average pooling\n",
    "    outputs = Dense(100, activation='softmax')(x)  # Assume 100-class classification\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Get Image Files \n",
    "def get_image_files(dataset_dir):\n",
    "    image_files = []\n",
    "    for root, dirs, files in os.walk(dataset_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                image_files.append(os.path.join(root, file))\n",
    "    return image_files\n",
    "\n",
    "# Process Image \n",
    "def load_and_preprocess_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    img = img.resize((224, 224))\n",
    "    img_array = np.array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = img_array / 255.0\n",
    "    return img_array\n",
    "\n",
    "# GPU Synchronization and Cache Clearing \n",
    "def gpu_synchronize_and_clear():\n",
    "    tf.config.experimental.set_synchronous_execution(True)  # Force GPU synchronization\n",
    "    tf.keras.backend.clear_session()  # Clear GPU cache\n",
    "\n",
    "# Preload All Images to Memory \n",
    "def preload_all_images_to_memory(image_files):\n",
    "    \"\"\"Preload all images into memory to avoid frequent disk access during inference.\"\"\"\n",
    "    preloaded_images = {}\n",
    "    for image_file in image_files:\n",
    "        img_array = load_and_preprocess_image(image_file)\n",
    "        preloaded_images[image_file] = img_array\n",
    "    return preloaded_images\n",
    "\n",
    "# Inference Function \n",
    "def inference_with_separate_timing(model, images, num_images):\n",
    "    gpu_synchronize_and_clear()  # Clear cache and synchronize GPU\n",
    "\n",
    "    # Perform inference and time it\n",
    "    t1 = time.time()\n",
    "    model.predict(images)\n",
    "    gpu_synchronize_and_clear()  # Synchronize GPU again\n",
    "\n",
    "    t2 = time.time()\n",
    "    inference_time = t2 - t1  # Record inference time\n",
    "    return inference_time\n",
    "\n",
    "# Single Image Inference \n",
    "def single_image_inference(model, image_files):\n",
    "    random_image_file = random.choice(image_files)\n",
    "    \n",
    "    # Record image loading and preprocessing time\n",
    "    image_data = load_and_preprocess_image(random_image_file)\n",
    "    \n",
    "    # Perform inference and record inference time\n",
    "    inference_time = inference_with_separate_timing(model, image_data, 1)\n",
    "    return inference_time, random_image_file\n",
    "\n",
    "# Batch Image Inference \n",
    "def batch_image_inference_and_async_loading(model, preloaded_images, image_files, batch_size):\n",
    "    t1 = time.time()\n",
    "    for img in random.sample(image_files, batch_size):\n",
    "        img = preloaded_images[img]\n",
    "        model.predict(img)\n",
    "    t2 = time.time()\n",
    "    inference_time = t2 - t1\n",
    "    average_time_per_image = inference_time / batch_size\n",
    "    return inference_time, average_time_per_image\n",
    "\n",
    "# Main Program Entry \n",
    "if __name__ == \"__main__\":\n",
    "    dataset_dir = \"../data\"  # Set dataset directory\n",
    "    model = create_model()\n",
    "\n",
    "    # Model warm-up\n",
    "    model(np.zeros((1, 224, 224, 3)))\n",
    "\n",
    "    # Get image files\n",
    "    image_files = get_image_files(dataset_dir)\n",
    "\n",
    "    # Preload all images into memory\n",
    "    preloaded_images = preload_all_images_to_memory(image_files)\n",
    "\n",
    "    # Calculate inference time for 1 image, 500 images, and 1000 images\n",
    "    for batch_size in [1, 500, 1000]:\n",
    "        if batch_size == 1:\n",
    "            inference_time, image_used = single_image_inference(model, image_files)\n",
    "            print(f\"Single image inference time: {inference_time * 1000:.4f} ms\")\n",
    "        else:\n",
    "            inference_time, avg_time_per_image = batch_image_inference_and_async_loading(model, preloaded_images, image_files, batch_size)\n",
    "            print(f\"Batch of {batch_size} images inference time: {inference_time * 1000:.4f} ms\")\n",
    "            print(f\"Average time per image in batch of {batch_size}: {avg_time_per_image * 1000:.4f} ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
